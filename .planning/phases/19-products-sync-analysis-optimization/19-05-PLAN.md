---
phase: 19-products-sync-analysis-optimization
plan: 05
title: Comprehensive Testing & Performance Validation
subsystem: testing
complexity: low
estimated_duration: 45min
tags: [testing, performance, benchmarks, validation]
---

# Plan 19-05: Comprehensive Testing & Performance Validation

## Objective

Create comprehensive test suite for PDF-based products sync: Python unit tests, Node.js integration tests, performance benchmarks, and UAT checklist, following Phase 18-05 patterns.

## Execution Context

**Phase 18-05 Proven Patterns:**
- Python unittest for parser validation
- Vitest for Node.js integration tests
- Bash benchmark script with statistics
- TEST-RESULTS.md documentation
- UAT checklist for manual validation
- skipInCI pattern for tests requiring credentials

**User Requirements:**
- Validate ~4,540 products sync
- Performance target: <60s total sync time
- All PDF fields coverage (26+ fields)
- No image management tests (eliminated)

**Key Files:**
- Reference: `.planning/phases/18-customers-sync-analysis-optimization/18-05-PLAN.md`
- Reference: `scripts/test_parse_clienti_pdf.py`
- Reference: `scripts/benchmark-sync.sh`
- Target: Create test suite for products sync

## Context

**Dependencies:**
- Phase 19-04 complete (full sync pipeline working)
- Test patterns established in Phase 18-05

**Performance Targets:**
- PDF download: 8-10s (vs 5-8s customers - larger file)
- PDF parsing: ~18s (vs ~6s customers - 3x records)
- Delta detection: 3-4s (vs 1-2s customers)
- DB updates: 3-5s (vs 1-2s customers)
- **Total: <60s** (vs 15-20s customers)

## Tasks

### Task 1: Create Python Unit Tests
**Duration:** 15min

Create `scripts/test_parse_products_pdf.py`.

**Implementation:**
```python
import unittest
import sys
import os
from parse_products_pdf import ProductsPDFParser

class TestProductsPDFParser(unittest.TestCase):
    """Unit tests for products PDF parser"""

    def setUp(self):
        """Set up test fixtures"""
        self.pdf_path = os.getenv('PRODUCTS_PDF_PATH', '/tmp/articoli-test.pdf')

        if not os.path.exists(self.pdf_path):
            self.skipTest(f"Test PDF not found: {self.pdf_path}")

        self.parser = ProductsPDFParser(self.pdf_path)

    def test_parser_initialization(self):
        """Parser initializes successfully"""
        self.assertIsNotNone(self.parser)
        self.assertGreater(self.parser.total_pages, 0)

    def test_parse_returns_products(self):
        """Parser returns list of products"""
        products = self.parser.parse()
        self.assertIsInstance(products, list)
        self.assertGreater(len(products), 0)

    def test_garbage_filtering(self):
        """Garbage records (ID='0') are filtered out"""
        products = self.parser.parse()
        for product in products:
            self.assertNotEqual(product.id_articolo, '0')
            self.assertNotEqual(product.id_articolo.strip(), '')

    def test_valid_product_count(self):
        """Product count is within expected range (~4,540)"""
        products = self.parser.parse()
        self.assertGreaterEqual(len(products), 4000)
        self.assertLessEqual(len(products), 5000)

    def test_required_fields_present(self):
        """All products have required fields (ID, name)"""
        products = self.parser.parse()
        for product in products[:10]:  # Check first 10
            self.assertIsNotNone(product.id_articolo)
            self.assertIsNotNone(product.nome_articolo)

    def test_page_4_8_fields_present(self):
        """Products have fields from pages 4-8 (extended fields)"""
        products = self.parser.parse()
        products_with_extended = [
            p for p in products
            if p.figura or p.grandezza or p.purch_price
        ]
        # At least 50% should have extended fields
        self.assertGreater(len(products_with_extended), len(products) * 0.5)

    def test_all_26_fields_available(self):
        """All 26+ PDF fields are available in dataclass"""
        products = self.parser.parse()
        if len(products) > 0:
            product = products[0]
            # Check all field names exist
            expected_fields = [
                'id_articolo', 'nome_articolo', 'descrizione',
                'gruppo_articolo', 'contenuto_imballaggio', 'nome_ricerca',
                'unita_prezzo', 'id_gruppo_prodotti', 'descrizione_gruppo_articolo', 'qta_minima',
                'qta_multipli', 'qta_massima', 'figura', 'id_blocco_articolo', 'pacco_gamba',
                'grandezza', 'id_configurazione', 'creato_da', 'data_creata', 'dataareaid',
                'qta_predefinita', 'visualizza_numero_prodotto', 'sconto_assoluto_totale', 'id_prodotto',
                'sconto_linea', 'modificato_da', 'datetime_modificato', 'articolo_ordinabile',
                'purch_price', 'pcs_id_configurazione_standard', 'qta_standard', 'fermato', 'id_unita'
            ]
            for field in expected_fields:
                self.assertTrue(hasattr(product, field))

    def test_performance_target(self):
        """Parser meets performance target (<18s for ~4,540 products)"""
        import time
        start = time.time()
        products = self.parser.parse()
        duration = time.time() - start

        print(f"\n‚úÖ Parsed {len(products)} products in {duration:.2f}s")
        self.assertLess(duration, 18, f"Parse time {duration:.2f}s exceeds 18s target")

if __name__ == '__main__':
    # Run with verbose output
    unittest.main(verbosity=2)
```

**Acceptance Criteria:**
- 8 unit tests for parser validation
- Garbage filtering verified
- Field coverage 100% (26+ fields)
- Performance target <18s
- Skip if test PDF not found

**Commit:** `test(19-05): add Python unit tests for products PDF parser`

---

### Task 2: Create Node.js Integration Tests
**Duration:** 15min

Create integration tests in `archibald-web-app/backend/src/`.

**pdf-parser-products-service.test.ts:**
```typescript
import { describe, test, expect, beforeAll } from 'vitest';
import { PDFParserProductsService } from './pdf-parser-products-service';
import path from 'path';

const skipInCI = () => {
  if (process.env.CI) {
    console.warn('‚è≠Ô∏è  Skipping test in CI (requires Archibald credentials)');
    return true;
  }
  return false;
};

describe('PDFParserProductsService', () => {
  let service: PDFParserProductsService;
  let testPdfPath: string;

  beforeAll(() => {
    if (skipInCI()) return;

    service = PDFParserProductsService.getInstance();
    testPdfPath = process.env.PRODUCTS_PDF_PATH || '/tmp/articoli-test.pdf';
  });

  test('should parse PDF successfully', async () => {
    if (skipInCI()) return;

    const products = await service.parsePDF(testPdfPath);

    expect(products).toBeInstanceOf(Array);
    expect(products.length).toBeGreaterThan(0);
  });

  test('should return ~4,540 valid products', async () => {
    if (skipInCI()) return;

    const products = await service.parsePDF(testPdfPath);

    expect(products.length).toBeGreaterThanOrEqual(4000);
    expect(products.length).toBeLessThanOrEqual(5000);
  });

  test('should have all 26+ business fields', async () => {
    if (skipInCI()) return;

    const products = await service.parsePDF(testPdfPath);
    const sample = products[0];

    // Check core fields
    expect(sample.id_articolo).toBeDefined();
    expect(sample.nome_articolo).toBeDefined();

    // Check extended fields from pages 4-8
    // At least some should be populated
    const hasExtendedFields = [
      sample.figura,
      sample.grandezza,
      sample.purch_price,
      sample.fermato,
    ].some(field => field !== undefined && field !== null);

    expect(hasExtendedFields).toBe(true);
  });

  test('should parse within performance target (<20s)', async () => {
    if (skipInCI()) return;

    const start = Date.now();
    const products = await service.parsePDF(testPdfPath);
    const duration = Date.now() - start;

    console.log(`‚úÖ Parsed ${products.length} products in ${duration}ms`);
    expect(duration).toBeLessThan(20000); // 20s buffer
  });

  test('should pass health check', async () => {
    if (skipInCI()) return;

    const health = await service.healthCheck();

    expect(health.healthy).toBe(true);
    expect(health.pythonVersion).toBeDefined();
    expect(health.pyPDF2Available).toBe(true);
  });

  test('should throw error for non-existent PDF', async () => {
    if (skipInCI()) return;

    await expect(
      service.parsePDF('/tmp/non-existent.pdf')
    ).rejects.toThrow();
  });
});
```

**product-sync-pdf.test.ts:**
```typescript
import { describe, test, expect, beforeAll } from 'vitest';
import { ProductSyncService } from './product-sync-service';

const skipInCI = () => {
  if (process.env.CI) {
    console.warn('‚è≠Ô∏è  Skipping test in CI (requires Archibald credentials)');
    return true;
  }
  return false;
};

describe('ProductSyncService (PDF-based)', () => {
  let service: ProductSyncService;

  beforeAll(() => {
    if (skipInCI()) return;
    service = ProductSyncService.getInstance();
  });

  test('should sync products successfully', async () => {
    if (skipInCI()) return;

    const start = Date.now();
    const result = await service.syncProducts();
    const duration = Date.now() - start;

    expect(result.productsProcessed).toBeGreaterThan(4000);
    expect(duration).toBeLessThan(65000); // 65s buffer (target 60s)

    console.log(`‚úÖ Synced ${result.productsProcessed} products in ${duration}ms`);
  }, 120000); // 120s timeout

  test('should detect new products on first sync', async () => {
    if (skipInCI()) return;

    // This test assumes DB is empty or has outdated data
    const result = await service.syncProducts();

    expect(result.newProducts).toBeGreaterThan(0);
  }, 120000);

  test('should skip unchanged products on second sync', async () => {
    if (skipInCI()) return;

    // First sync
    await service.syncProducts();

    // Second sync (no changes)
    const result = await service.syncProducts();

    expect(result.newProducts).toBe(0);
    expect(result.updatedProducts).toBe(0);
  }, 240000); // 240s for two syncs

  test('should prevent concurrent syncs', async () => {
    if (skipInCI()) return;

    // Start first sync (don't await)
    const sync1 = service.syncProducts();

    // Try concurrent sync
    await expect(service.syncProducts()).rejects.toThrow('Sync already in progress');

    // Wait for first to complete
    await sync1;
  }, 120000);

  test('should track metrics correctly', async () => {
    if (skipInCI()) return;

    const db = service['db']; // Access private field for testing
    const metricsBefore = db.getSyncMetrics();

    await service.syncProducts();

    const metricsAfter = db.getSyncMetrics();

    expect(metricsAfter.totalSyncs).toBe(metricsBefore.totalSyncs + 1);
  }, 120000);

  test('should validate sync duration within target', async () => {
    if (skipInCI()) return;

    const start = Date.now();
    await service.syncProducts();
    const duration = Date.now() - start;

    console.log(`‚è±Ô∏è  Sync duration: ${duration}ms (target: <60000ms)`);
    expect(duration).toBeLessThan(60000);
  }, 120000);

  test('should have all 26+ fields in synced products', async () => {
    if (skipInCI()) return;

    await service.syncProducts();

    const db = service['db'];
    const products = db.getAllProducts();

    expect(products.length).toBeGreaterThan(4000);

    // Check sample product has extended fields
    const sample = products[0];
    expect(sample.id).toBeDefined();
    expect(sample.name).toBeDefined();
    // Check at least some extended fields populated
    const hasExtended = [
      sample.figure,
      sample.size,
      sample.purchPrice,
    ].some(f => f !== undefined);

    expect(hasExtended).toBe(true);
  }, 120000);
});
```

**Acceptance Criteria:**
- 6 tests for PDF parser service
- 7 tests for sync service
- All tests use skipInCI pattern
- Performance targets validated
- Field coverage verified

**Commit:** `test(19-05): add Node.js integration tests for products sync`

---

### Task 3: Create Performance Benchmark Script
**Duration:** 10min

Create `scripts/benchmark-products-sync.sh`.

**Implementation:**
```bash
#!/bin/bash

# Performance benchmark for products sync (5 iterations)

set -e

ITERATIONS=5
API_URL="${API_URL:-http://localhost:3000}"
ENDPOINT="/api/products/sync"

# Check JWT token
if [ -z "$JWT_TOKEN" ]; then
  echo "‚ùå Error: JWT_TOKEN environment variable not set"
  echo "Usage: JWT_TOKEN='your-token' ./benchmark-products-sync.sh"
  exit 1
fi

echo "=== Products Sync Performance Benchmark ==="
echo ""
echo "Iterations: $ITERATIONS"
echo "Endpoint: $API_URL$ENDPOINT"
echo ""

declare -a durations
total_duration=0
success_count=0

for i in $(seq 1 $ITERATIONS); do
  echo "Run $i/$ITERATIONS..."

  start=$(date +%s%3N)

  response=$(curl -s -w "\n%{http_code}" \
    -X POST \
    -H "Authorization: Bearer $JWT_TOKEN" \
    -H "Content-Type: application/json" \
    "$API_URL$ENDPOINT")

  http_code=$(echo "$response" | tail -n 1)
  body=$(echo "$response" | sed '$d')

  end=$(date +%s%3N)
  duration=$((end - start))

  durations+=($duration)
  total_duration=$((total_duration + duration))

  if [ "$http_code" -eq 200 ]; then
    success_count=$((success_count + 1))
    products_processed=$(echo "$body" | jq -r '.productsProcessed // 0')
    new_products=$(echo "$body" | jq -r '.newProducts // 0')
    updated_products=$(echo "$body" | jq -r '.updatedProducts // 0')

    echo "  Duration: ${duration}ms"
    echo "  Success: true"
    echo "  Processed: $products_processed products"
    echo "  New: $new_products, Updated: $updated_products"
  else
    echo "  Duration: ${duration}ms"
    echo "  Success: false (HTTP $http_code)"
    echo "  Error: $body"
  fi

  echo ""
done

# Calculate statistics
avg_duration=$((total_duration / ITERATIONS))
min_duration=${durations[0]}
max_duration=${durations[0]}

for duration in "${durations[@]}"; do
  if [ $duration -lt $min_duration ]; then
    min_duration=$duration
  fi
  if [ $duration -gt $max_duration ]; then
    max_duration=$duration
  fi
done

echo "=== Summary ==="
echo "Successful runs: $success_count/$ITERATIONS"
echo "Average: ${avg_duration}ms"
echo "Min: ${min_duration}ms"
echo "Max: ${max_duration}ms"
echo ""

# Validate target (<60s)
if [ $avg_duration -lt 60000 ]; then
  echo "‚úÖ PASS: Average within target (<60s)"
  exit 0
else
  echo "‚ùå FAIL: Average exceeds target (${avg_duration}ms > 60000ms)"
  exit 1
fi
```

**Acceptance Criteria:**
- 5-iteration benchmark
- JWT authentication
- Statistics (avg, min, max)
- Target validation (<60s)
- Exit code 0/1

**Commit:** `test(19-05): add performance benchmark script for products sync`

---

### Task 4: Create TEST-RESULTS.md Documentation
**Duration:** 5min

Create comprehensive test results document.

**File:** `.planning/phases/19-products-sync-analysis-optimization/TEST-RESULTS.md`

**Content:**
```markdown
# Phase 19 Test Results - PDF-Based Products Sync

**Test Date:** 2026-01-XX
**Phase:** 19 (Products Sync Analysis & Optimization)
**Status:** ‚è≥ TESTS PENDING EXECUTION

## Test Summary

| Category | Tests | Passed | Failed | Coverage | Status |
|----------|-------|--------|--------|----------|--------|
| Unit (Python) | 8 | 0 | 0 | 100% | ‚è≥ Pending |
| Integration (Node) | 13 | 0 | 0 | 100% | ‚è≥ Pending |
| Performance | 3 | 0 | 0 | ‚úÖ Targets defined | ‚è≥ Pending |

**Overall: 0/24 tests executed** ‚è≥

## Performance Targets

### Full Sync Benchmark
- **Target:** <60s for ~4,540 products
- **Breakdown:**
  - Bot login + PDF download: 8-10s (17%)
  - PDF parsing: ~18s (30%)
  - Delta detection: 3-4s (7%)
  - DB updates: 3-5s (8%)

### Comparison vs HTML Scraping
| Metric | HTML (Old) | PDF (New) | Improvement |
|--------|-----------|-----------|-------------|
| Full sync | 90-120s | <60s | **50% faster** |
| Stability | Low (UI-dependent) | High (file format) | Much more stable |
| Code complexity | ~1,200 lines | ~400 lines | **67% less code** |
| Image management | ~500 lines | 0 lines (eliminated) | **100% removed** |

## Execution Instructions

### Python Unit Tests
```bash
cd scripts
PRODUCTS_PDF_PATH=/path/to/articoli.pdf python3 test_parse_products_pdf.py -v
```

### Node.js Integration Tests
```bash
cd archibald-web-app/backend
PRODUCTS_PDF_PATH=/path/to/articoli.pdf npm test -- pdf-parser-products-service.test.ts
PRODUCTS_PDF_PATH=/path/to/articoli.pdf npm test -- product-sync-pdf.test.ts
```

### Performance Benchmark
```bash
JWT_TOKEN='your-jwt-token' ./scripts/benchmark-products-sync.sh
```

## UAT Checklist

### Scenario 1: Manual Sync
- [ ] Navigate to Articoli page
- [ ] Click "üîÑ Aggiorna Articoli" button
- [ ] Yellow banner appears: "‚è≥ Aggiornamento articoli in corso..."
- [ ] Wait ~60s
- [ ] Green banner appears: "‚úÖ X nuovi, Y aggiornati"
- [ ] Banner auto-hides after 3s
- [ ] Products list refreshes

**Result:** ‚è≥ PENDING

### Scenario 2: Background Sync
- [ ] Wait 30 minutes
- [ ] Observe backend logs for automatic sync
- [ ] Check /api/products/sync/metrics for history
- [ ] Verify no interruption to user workflow

**Result:** ‚è≥ PENDING

### Scenario 3: Error Handling
- [ ] Simulate network failure
- [ ] Click manual sync
- [ ] Observe 3 retry attempts
- [ ] Red banner with error message
- [ ] Restore network and retry

**Result:** ‚è≥ PENDING

## Production Readiness Criteria

- [ ] All unit tests passing (8/8)
- [ ] All integration tests passing (13/13)
- [ ] Performance target achieved (<60s average)
- [ ] Field coverage 100% (26+ fields)
- [ ] Error handling validated (retry, alerts)
- [ ] UAT scenarios pass
- [ ] Documentation complete

**Production Approval:** ‚è≥ PENDING
```

**Acceptance Criteria:**
- Comprehensive test documentation
- Execution instructions clear
- UAT scenarios defined
- Performance targets documented

**Commit:** `docs(19-05): create test results documentation for Phase 19`

---

## Verification

### Manual Execution

**Step 1: Python Unit Tests**
```bash
cd scripts
PRODUCTS_PDF_PATH=/tmp/articoli-test.pdf python3 test_parse_products_pdf.py -v
```

**Step 2: Node.js Integration Tests**
```bash
cd archibald-web-app/backend
PRODUCTS_PDF_PATH=/tmp/articoli-test.pdf npm test
```

**Step 3: Performance Benchmark**
```bash
JWT_TOKEN='your-token' ./scripts/benchmark-products-sync.sh
```

**Step 4: Update TEST-RESULTS.md**

Update test status and results after execution.

## Success Criteria

- [ ] Python unit tests created (8 tests)
- [ ] Node.js integration tests created (13 tests)
- [ ] Performance benchmark script created
- [ ] TEST-RESULTS.md documentation complete
- [ ] All tests use skipInCI pattern
- [ ] Performance targets validated (<60s)
- [ ] Field coverage verified (26+ fields)
- [ ] UAT checklist defined
- [ ] All commits atomic with proper messages

## Output

**Files Created:**
- `scripts/test_parse_products_pdf.py` (~150 lines)
- `archibald-web-app/backend/src/pdf-parser-products-service.test.ts` (~90 lines)
- `archibald-web-app/backend/src/product-sync-pdf.test.ts` (~130 lines)
- `scripts/benchmark-products-sync.sh` (~80 lines)
- `.planning/phases/19-products-sync-analysis-optimization/TEST-RESULTS.md` (~300 lines)

**Commits:** 4 atomic commits

**Next Phase:** Phase 20 (Prices Sync Analysis & Optimization)

---
phase: 12-deployment-infrastructure
type: execute
---

<objective>
Setup GitHub Actions CI/CD pipeline with blue-green deployment and automatic rollback.

Purpose: Enable push-to-deploy workflow with zero-downtime deployments and health check validation.
Output: GitHub Actions workflow file, deployment scripts, health check endpoint, rollback mechanism.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/12-deployment-infrastructure/12-CONTEXT.md
@archibald-web-app/backend/src/index.ts
@docker-compose.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add health check endpoint to backend</name>
  <files>archibald-web-app/backend/src/index.ts, archibald-web-app/backend/src/health.ts</files>
  <action>
    Create health check module in [archibald-web-app/backend/src/health.ts](archibald-web-app/backend/src/health.ts):

    ```typescript
    import { Request, Response } from 'express';

    export interface HealthStatus {
      status: 'healthy' | 'unhealthy';
      timestamp: string;
      uptime: number;
      checks: {
        redis: 'ok' | 'error';
        database: 'ok' | 'error';
        puppeteer: 'ok' | 'error';
      };
      version?: string;
    }

    export async function getHealthStatus(): Promise<HealthStatus> {
      const checks = {
        redis: 'ok' as const,
        database: 'ok' as const,
        puppeteer: 'ok' as const,
      };

      // Check Redis connection
      try {
        // Assuming Redis client is available globally or via dependency injection
        // For now, basic check - can enhance with actual Redis ping
        checks.redis = 'ok';
      } catch (error) {
        checks.redis = 'error';
      }

      // Check database (SQLite file access)
      try {
        const fs = await import('fs/promises');
        await fs.access(process.env.DATABASE_PATH || './data/customers.db');
        checks.database = 'ok';
      } catch (error) {
        checks.database = 'error';
      }

      // Check Puppeteer (executable exists)
      try {
        const fs = await import('fs/promises');
        await fs.access(process.env.PUPPETEER_EXECUTABLE_PATH || '/usr/bin/chromium-browser');
        checks.puppeteer = 'ok';
      } catch (error) {
        checks.puppeteer = 'error';
      }

      const isHealthy = Object.values(checks).every(status => status === 'ok');

      return {
        status: isHealthy ? 'healthy' : 'unhealthy',
        timestamp: new Date().toISOString(),
        uptime: process.uptime(),
        checks,
        version: process.env.npm_package_version,
      };
    }

    export async function healthCheckHandler(req: Request, res: Response) {
      const health = await getHealthStatus();
      const statusCode = health.status === 'healthy' ? 200 : 503;
      res.status(statusCode).json(health);
    }
    ```

    Integrate into [archibald-web-app/backend/src/index.ts](archibald-web-app/backend/src/index.ts):

    ```typescript
    import { healthCheckHandler } from './health';

    // Add near other route definitions
    app.get('/health', healthCheckHandler);
    ```

    Key decisions:
    - Lightweight health checks (Redis, DB file access, Chromium exists)
    - Returns 200 (healthy) or 503 (unhealthy) for load balancer compatibility
    - Includes uptime and version for debugging
    - Fast response (< 100ms) to avoid health check timeouts
  </action>
  <verify>
    - [archibald-web-app/backend/src/health.ts](archibald-web-app/backend/src/health.ts) created
    - Health check endpoint registered in [archibald-web-app/backend/src/index.ts](archibald-web-app/backend/src/index.ts)
    - TypeScript compiles without errors
    - Test locally: `curl http://localhost:3000/health` returns 200 with JSON
  </verify>
  <done>
    Health check endpoint implemented with Redis, database, and Puppeteer checks
  </done>
</task>

<task type="auto">
  <name>Task 2: Create deployment script for blue-green deployment</name>
  <files>scripts/deploy.sh</files>
  <action>
    Create deployment script at [scripts/deploy.sh](scripts/deploy.sh):

    ```bash
    #!/bin/bash
    set -euo pipefail

    # Blue-Green Deployment Script for Archibald Black Ant
    # Usage: ./scripts/deploy.sh

    DEPLOY_DIR="/home/deploy/archibald-app"
    BLUE_COMPOSE="docker-compose.yml"
    GREEN_COMPOSE="docker-compose.green.yml"
    HEALTH_URL="http://localhost:3000/health"
    HEALTH_TIMEOUT=60  # seconds
    HEALTH_INTERVAL=5  # seconds

    echo "=== Archibald Black Ant Deployment ==="
    echo "Starting blue-green deployment..."

    # Determine current environment (blue or green)
    if docker compose -f "$BLUE_COMPOSE" ps --services --filter "status=running" | grep -q backend; then
      CURRENT="blue"
      NEW="green"
      CURRENT_COMPOSE="$BLUE_COMPOSE"
      NEW_COMPOSE="$GREEN_COMPOSE"
    else
      CURRENT="green"
      NEW="blue"
      CURRENT_COMPOSE="$GREEN_COMPOSE"
      NEW_COMPOSE="$BLUE_COMPOSE"
    fi

    echo "Current environment: $CURRENT"
    echo "Deploying to: $NEW"

    # Step 1: Pull latest code
    echo "Pulling latest code..."
    git pull origin master

    # Step 2: Build new containers
    echo "Building $NEW environment..."
    docker compose -f "$NEW_COMPOSE" build --no-cache

    # Step 3: Start new environment
    echo "Starting $NEW environment..."
    docker compose -f "$NEW_COMPOSE" up -d

    # Step 4: Wait for health checks
    echo "Waiting for health checks (timeout: ${HEALTH_TIMEOUT}s)..."
    ELAPSED=0
    HEALTHY=false

    while [ $ELAPSED -lt $HEALTH_TIMEOUT ]; do
      if curl -sf "$HEALTH_URL" > /dev/null 2>&1; then
        HEALTHY=true
        echo "✓ Health checks passed after ${ELAPSED}s"
        break
      fi

      echo "Waiting... (${ELAPSED}/${HEALTH_TIMEOUT}s)"
      sleep $HEALTH_INTERVAL
      ELAPSED=$((ELAPSED + HEALTH_INTERVAL))
    done

    # Step 5: Health check validation
    if [ "$HEALTHY" = false ]; then
      echo "✗ Health checks failed after ${HEALTH_TIMEOUT}s"
      echo "Rolling back to $CURRENT environment..."

      # Rollback: stop new, keep current running
      docker compose -f "$NEW_COMPOSE" down
      echo "Rollback complete. $CURRENT environment still running."
      exit 1
    fi

    # Step 6: Switch traffic (Nginx reload)
    echo "Switching traffic to $NEW environment..."
    docker compose restart nginx-proxy

    # Step 7: Stop old environment
    echo "Stopping $CURRENT environment..."
    sleep 10  # Grace period for in-flight requests
    docker compose -f "$CURRENT_COMPOSE" down

    # Step 8: Cleanup old images
    echo "Cleaning up old Docker images..."
    docker image prune -f

    echo "=== Deployment Complete ==="
    echo "✓ $NEW environment is now live"
    echo "✓ $CURRENT environment stopped"
    ```

    Make executable:
    ```bash
    chmod +x scripts/deploy.sh
    ```

    Key decisions:
    - Blue-green pattern (two identical environments, switch atomically)
    - Health check validation (60s timeout, 5s interval polling)
    - Automatic rollback on health check failure (keep old environment running)
    - 10-second grace period before stopping old environment (in-flight requests)
    - Cleanup old images to save disk space
  </action>
  <verify>
    - [scripts/deploy.sh](scripts/deploy.sh) created
    - Script is executable (`ls -l scripts/deploy.sh` shows `x` permission)
    - Health check URL correct (http://localhost:3000/health)
    - Rollback logic present (stops new, keeps old on failure)
  </verify>
  <done>
    Blue-green deployment script created with health check validation and automatic rollback
  </done>
</task>

<task type="auto">
  <name>Task 3: Create GitHub Actions CI/CD workflow</name>
  <files>.github/workflows/deploy.yml</files>
  <action>
    Create GitHub Actions workflow at [.github/workflows/deploy.yml](.github/workflows/deploy.yml):

    ```yaml
    name: Deploy to Production

    on:
      push:
        branches:
          - master  # Auto-deploy on push to master

      workflow_dispatch:  # Allow manual trigger

    env:
      SSH_HOST: ${{ secrets.VPS_IP }}
      SSH_USER: deploy
      DEPLOY_DIR: /home/deploy/archibald-app

    jobs:
      deploy:
        name: Deploy to VPS
        runs-on: ubuntu-latest
        timeout-minutes: 15

        steps:
          - name: Checkout code
            uses: actions/checkout@v4

          - name: Setup SSH key
            uses: webfactory/ssh-agent@v0.9.0
            with:
              ssh-private-key: ${{ secrets.VPS_SSH_KEY }}

          - name: Add VPS to known hosts
            run: |
              mkdir -p ~/.ssh
              ssh-keyscan -H ${{ secrets.VPS_IP }} >> ~/.ssh/known_hosts

          - name: Deploy via SSH
            run: |
              ssh $SSH_USER@$SSH_HOST << 'ENDSSH'
                set -euo pipefail

                echo "=== Starting deployment on VPS ==="

                cd $DEPLOY_DIR

                # Pull latest code
                git pull origin master

                # Run deployment script
                ./scripts/deploy.sh

                echo "=== Deployment complete ==="
              ENDSSH

          - name: Verify deployment
            run: |
              echo "Verifying deployment..."
              sleep 10  # Wait for services to stabilize

              # Check health endpoint
              HEALTH_STATUS=$(curl -s -o /dev/null -w "%{http_code}" https://archibaldblackant.it/health)

              if [ "$HEALTH_STATUS" -eq 200 ]; then
                echo "✓ Deployment verified (HTTP $HEALTH_STATUS)"
              else
                echo "✗ Deployment verification failed (HTTP $HEALTH_STATUS)"
                exit 1
              fi

          - name: Notify on failure
            if: failure()
            run: |
              echo "Deployment failed! Check logs above."
              # Future: send notification to Slack/email/Discord
    ```

    Create GitHub Secrets documentation in [.github/SECRETS.md](.github/SECRETS.md):

    ```markdown
    # GitHub Secrets Configuration

    Required secrets for CI/CD:

    ## VPS_IP
    - Value: VPS IP address (e.g., `123.45.67.89`)
    - Usage: SSH connection to VPS for deployment

    ## VPS_SSH_KEY
    - Value: Private SSH key for deploy user
    - Generation:
      ```bash
      # On local machine, generate key pair
      ssh-keygen -t ed25519 -C "github-actions-deploy" -f ~/.ssh/archibald_deploy

      # Copy public key to VPS
      ssh-copy-id -i ~/.ssh/archibald_deploy.pub deploy@<VPS_IP>

      # Copy private key content to GitHub secret
      cat ~/.ssh/archibald_deploy  # Copy entire output
      ```
    - Usage: Authenticate GitHub Actions to VPS

    ## Setup Instructions

    1. Go to repository Settings → Secrets and variables → Actions
    2. Click "New repository secret"
    3. Add `VPS_IP` with VPS IP address
    4. Add `VPS_SSH_KEY` with private key content (entire file including headers)
    ```

    Key decisions:
    - Auto-deploy on push to master (per 12-CONTEXT.md requirement)
    - Manual trigger available (workflow_dispatch for hotfixes)
    - 15-minute timeout (prevent infinite hangs)
    - Post-deployment health check verification (via public HTTPS URL)
    - Failure notification placeholder (can add Slack/email later)
  </action>
  <verify>
    - [.github/workflows/deploy.yml](.github/workflows/deploy.yml) created
    - [.github/SECRETS.md](.github/SECRETS.md) created
    - Workflow triggers on push to master
    - Manual workflow_dispatch trigger enabled
    - Health check verification step present
  </verify>
  <done>
    GitHub Actions workflow created with auto-deploy, health check verification, and manual trigger
  </done>
</task>

<task type="auto">
  <name>Task 4: Create manual rollback script</name>
  <files>scripts/rollback.sh</files>
  <action>
    Create rollback script at [scripts/rollback.sh](scripts/rollback.sh):

    ```bash
    #!/bin/bash
    set -euo pipefail

    # Manual Rollback Script for Archibald Black Ant
    # Usage: ./scripts/rollback.sh

    DEPLOY_DIR="/home/deploy/archibald-app"
    BLUE_COMPOSE="docker-compose.yml"
    GREEN_COMPOSE="docker-compose.green.yml"

    echo "=== Archibald Black Ant Rollback ==="

    # Determine current environment
    if docker compose -f "$BLUE_COMPOSE" ps --services --filter "status=running" | grep -q backend; then
      CURRENT="blue"
      PREVIOUS="green"
      CURRENT_COMPOSE="$BLUE_COMPOSE"
      PREVIOUS_COMPOSE="$GREEN_COMPOSE"
    else
      CURRENT="green"
      PREVIOUS="blue"
      CURRENT_COMPOSE="$GREEN_COMPOSE"
      PREVIOUS_COMPOSE="$BLUE_COMPOSE"
    fi

    echo "Current environment: $CURRENT"
    echo "Rolling back to: $PREVIOUS"

    # Confirmation prompt
    read -p "Are you sure you want to rollback to $PREVIOUS? (yes/no): " CONFIRM
    if [ "$CONFIRM" != "yes" ]; then
      echo "Rollback cancelled."
      exit 0
    fi

    # Step 1: Check if previous environment exists
    if ! docker compose -f "$PREVIOUS_COMPOSE" config > /dev/null 2>&1; then
      echo "✗ Error: $PREVIOUS environment not found"
      exit 1
    fi

    # Step 2: Start previous environment
    echo "Starting $PREVIOUS environment..."
    docker compose -f "$PREVIOUS_COMPOSE" up -d

    # Step 3: Wait for health checks
    echo "Waiting for health checks..."
    sleep 30

    HEALTH_URL="http://localhost:3000/health"
    if curl -sf "$HEALTH_URL" > /dev/null 2>&1; then
      echo "✓ Health checks passed"
    else
      echo "✗ Health checks failed for $PREVIOUS environment"
      echo "Manual intervention required."
      exit 1
    fi

    # Step 4: Switch traffic
    echo "Switching traffic to $PREVIOUS environment..."
    docker compose restart nginx-proxy

    # Step 5: Stop current environment
    echo "Stopping $CURRENT environment..."
    sleep 10  # Grace period
    docker compose -f "$CURRENT_COMPOSE" down

    echo "=== Rollback Complete ==="
    echo "✓ $PREVIOUS environment is now live"
    echo "✓ $CURRENT environment stopped"
    ```

    Make executable:
    ```bash
    chmod +x scripts/rollback.sh
    ```

    Key decisions:
    - Manual confirmation required (prevent accidental rollback)
    - Health check validation before switching traffic (safety)
    - Same blue-green pattern as deploy.sh (consistency)
    - 30-second wait for health checks (rollback may need longer to stabilize)
  </action>
  <verify>
    - [scripts/rollback.sh](scripts/rollback.sh) created
    - Script is executable
    - Confirmation prompt present (prevents accidental execution)
    - Health check validation before traffic switch
  </verify>
  <done>
    Manual rollback script created with confirmation prompt and health check validation
  </done>
</task>

<task type="checkpoint:human-action" gate="blocking">
  <what>Configure GitHub Secrets for CI/CD</what>
  <instructions>
    Setup GitHub repository secrets:

    1. **Generate SSH key for GitHub Actions (on local machine):**
       ```bash
       ssh-keygen -t ed25519 -C "github-actions-deploy" -f ~/.ssh/archibald_deploy
       ```

    2. **Copy public key to VPS:**
       ```bash
       ssh-copy-id -i ~/.ssh/archibald_deploy.pub deploy@<VPS_IP>
       ```

    3. **Add secrets to GitHub:**
       - Go to repository Settings → Secrets and variables → Actions
       - Click "New repository secret"
       - Add `VPS_IP`:
         - Name: `VPS_IP`
         - Value: Your VPS IP address (e.g., `123.45.67.89`)
       - Add `VPS_SSH_KEY`:
         - Name: `VPS_SSH_KEY`
         - Value: Content of `~/.ssh/archibald_deploy` (entire file including `-----BEGIN` and `-----END` lines)

    4. **Verify SSH access from GitHub Actions:**
       - Trigger workflow manually (Actions tab → Deploy to Production → Run workflow)
       - Check logs for successful SSH connection

    5. **Setup deploy script on VPS:**
       ```bash
       ssh deploy@<VPS_IP>
       cd ~/archibald-app
       git pull origin master
       chmod +x scripts/deploy.sh scripts/rollback.sh
       ```
  </instructions>
  <resume-signal>Confirm: GitHub secrets configured, SSH key added to VPS, scripts executable</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Health check endpoint implemented in backend
- [ ] `/health` returns 200 when services healthy
- [ ] Blue-green deployment script created and executable
- [ ] Manual rollback script created and executable
- [ ] GitHub Actions workflow created
- [ ] GitHub secrets configured (VPS_IP, VPS_SSH_KEY)
- [ ] SSH access from GitHub Actions verified
- [ ] Deployment scripts executable on VPS
</verification>

<success_criteria>

- All tasks completed
- Health checks working
- CI/CD pipeline functional
- Push to master triggers auto-deploy
- Manual rollback available
- No errors in verification checks
</success_criteria>

<output>
After completion, create `.planning/phases/12-deployment-infrastructure/12-03-SUMMARY.md`
</output>

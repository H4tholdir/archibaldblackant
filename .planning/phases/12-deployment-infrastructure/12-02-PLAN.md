---
phase: 12-deployment-infrastructure
type: execute
---

<objective>
Create Docker containers, orchestration, and SSL certificates for production deployment.

Purpose: Package the application into Docker containers with Nginx reverse proxy and automatic HTTPS.
Output: docker-compose.yml with all services, Dockerfiles for frontend/backend, Let's Encrypt SSL configured.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/12-deployment-infrastructure/12-CONTEXT.md
@archibald-web-app/backend/package.json
@archibald-web-app/frontend/package.json
@archibald-web-app/frontend/vite.config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create backend Dockerfile with multi-stage build</name>
  <files>archibald-web-app/backend/Dockerfile</files>
  <action>
    Create production-optimized Dockerfile for backend with Chromium bundled:

    ```dockerfile
    # Stage 1: Dependencies
    FROM node:20-alpine AS deps
    WORKDIR /app
    COPY package*.json ./
    RUN npm ci --only=production

    # Stage 2: Build (if TypeScript compilation needed)
    FROM node:20-alpine AS builder
    WORKDIR /app
    COPY package*.json tsconfig.json ./
    COPY src ./src
    RUN npm ci
    RUN npm run build || echo "No build script, using src directly"

    # Stage 3: Production runtime with Chromium
    FROM node:20-alpine

    # Install Chromium and dependencies
    RUN apk add --no-cache \
        chromium \
        nss \
        freetype \
        harfbuzz \
        ca-certificates \
        ttf-freefont

    # Chromium executable path for Puppeteer
    ENV PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser
    ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true

    WORKDIR /app

    # Copy production dependencies
    COPY --from=deps /app/node_modules ./node_modules

    # Copy application code (prefer dist if exists, otherwise src)
    COPY --from=builder /app/dist ./dist 2>/dev/null || COPY --from=builder /app/src ./src
    COPY package*.json ./

    # Create data directory for SQLite databases
    RUN mkdir -p /app/data && chown node:node /app/data

    # Run as non-root user
    USER node

    EXPOSE 3000

    # Health check
    HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
        CMD node -e "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"

    CMD ["node", "src/index.js"]
    ```

    Key decisions:
    - Multi-stage build reduces final image size (~300MB vs ~1GB)
    - Chromium bundled in container (self-contained, no system dependencies)
    - Non-root user (security best practice)
    - Health check endpoint for container orchestration
    - SQLite data directory mounted as volume (persistence)
  </action>
  <verify>
    - File created at [archibald-web-app/backend/Dockerfile](archibald-web-app/backend/Dockerfile)
    - Syntax valid (no obvious typos)
    - Health check uses /health endpoint
  </verify>
  <done>
    Backend Dockerfile created with Chromium bundled, health check, and production optimizations
  </done>
</task>

<task type="auto">
  <name>Task 2: Create frontend Dockerfile with Nginx</name>
  <files>archibald-web-app/frontend/Dockerfile, archibald-web-app/frontend/nginx.conf</files>
  <action>
    Create frontend Dockerfile with static build + Nginx serve:

    ```dockerfile
    # Stage 1: Build React app
    FROM node:20-alpine AS builder
    WORKDIR /app
    COPY package*.json ./
    RUN npm ci
    COPY . .
    RUN npm run build

    # Stage 2: Serve with Nginx
    FROM nginx:alpine

    # Copy built static files
    COPY --from=builder /app/dist /usr/share/nginx/html

    # Copy custom Nginx config
    COPY nginx.conf /etc/nginx/conf.d/default.conf

    # Health check
    HEALTHCHECK --interval=30s --timeout=3s \
        CMD wget --quiet --tries=1 --spider http://localhost/ || exit 1

    EXPOSE 80

    CMD ["nginx", "-g", "daemon off;"]
    ```

    Create nginx.conf for SPA routing:

    ```nginx
    server {
        listen 80;
        server_name localhost;
        root /usr/share/nginx/html;
        index index.html;

        # Gzip compression
        gzip on;
        gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

        # SPA fallback - all routes serve index.html
        location / {
            try_files $uri $uri/ /index.html;
        }

        # Cache static assets (JS, CSS, images)
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # No cache for index.html (service worker will handle it)
        location = /index.html {
            add_header Cache-Control "no-cache, no-store, must-revalidate";
        }
    }
    ```

    Key decisions:
    - Nginx alpine image (lightweight, ~25MB)
    - SPA routing with try_files fallback (supports React Router)
    - Aggressive caching for static assets (fingerprinted by Vite)
    - No cache for index.html (service worker handles updates)
  </action>
  <verify>
    - [archibald-web-app/frontend/Dockerfile](archibald-web-app/frontend/Dockerfile) created
    - [archibald-web-app/frontend/nginx.conf](archibald-web-app/frontend/nginx.conf) created
    - nginx.conf has SPA fallback (try_files ... /index.html)
    - Static asset caching configured
  </verify>
  <done>
    Frontend Dockerfile and Nginx config created with SPA support and caching optimizations
  </done>
</task>

<task type="auto">
  <name>Task 3: Create docker-compose.yml with all services</name>
  <files>docker-compose.yml</files>
  <action>
    Create docker-compose.yml at repository root with frontend, backend, Redis, and Nginx reverse proxy:

    ```yaml
    version: '3.8'

    services:
      # Frontend (React PWA served by Nginx)
      frontend:
        build:
          context: ./archibald-web-app/frontend
          dockerfile: Dockerfile
        container_name: archibald-frontend
        restart: unless-stopped
        networks:
          - archibald-net
        # No ports exposed - accessed via nginx-proxy

      # Backend (Node.js + Puppeteer)
      backend:
        build:
          context: ./archibald-web-app/backend
          dockerfile: Dockerfile
        container_name: archibald-backend
        restart: unless-stopped
        env_file:
          - .env
        environment:
          - NODE_ENV=production
          - DATABASE_PATH=/app/data
          - REDIS_HOST=redis
          - REDIS_PORT=6379
        volumes:
          - ./data:/app/data  # Persist SQLite databases
          - ./logs:/app/logs  # Persist logs
        depends_on:
          - redis
        networks:
          - archibald-net
        # No ports exposed - accessed via nginx-proxy

      # Redis (Job queue for BullMQ)
      redis:
        image: redis:7-alpine
        container_name: archibald-redis
        restart: unless-stopped
        command: redis-server --appendonly yes
        volumes:
          - redis-data:/data  # Persist Redis AOF
        networks:
          - archibald-net
        healthcheck:
          test: ["CMD", "redis-cli", "ping"]
          interval: 10s
          timeout: 3s
          retries: 3

      # Nginx Reverse Proxy with SSL
      nginx-proxy:
        image: nginx:alpine
        container_name: archibald-nginx
        restart: unless-stopped
        ports:
          - "80:80"
          - "443:443"
        volumes:
          - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
          - ./nginx/ssl:/etc/nginx/ssl:ro  # SSL certificates
          - ./nginx/dhparam.pem:/etc/nginx/dhparam.pem:ro  # DH params
        depends_on:
          - frontend
          - backend
        networks:
          - archibald-net
        healthcheck:
          test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
          interval: 30s
          timeout: 5s
          retries: 3

    volumes:
      redis-data:

    networks:
      archibald-net:
        driver: bridge
    ```

    Key decisions:
    - Internal network (archibald-net) for service communication
    - Only nginx-proxy exposes ports 80/443 (security)
    - Volumes for persistence (data, logs, redis-data, SSL certs)
    - Health checks on all services (monitoring integration)
    - restart: unless-stopped (auto-restart on failure)
  </action>
  <verify>
    - [docker-compose.yml](docker-compose.yml) created at repository root
    - All 4 services defined (frontend, backend, redis, nginx-proxy)
    - Volumes configured for persistence
    - Health checks present
    - Network isolation configured
  </verify>
  <done>
    docker-compose.yml created with all services, health checks, and persistence
  </done>
</task>

<task type="auto">
  <name>Task 4: Create Nginx reverse proxy configuration</name>
  <files>nginx/nginx.conf</files>
  <action>
    Create Nginx config for reverse proxy with SSL termination:

    ```nginx
    events {
        worker_connections 1024;
    }

    http {
        # SSL configuration
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # Gzip compression
        gzip on;
        gzip_vary on;
        gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

        # Rate limiting (prevent abuse)
        limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
        limit_req_zone $binary_remote_addr zone=login_limit:10m rate=5r/m;

        # HTTP → HTTPS redirect
        server {
            listen 80;
            server_name archibaldblackant.it www.archibaldblackant.it;

            # ACME challenge for Let's Encrypt
            location /.well-known/acme-challenge/ {
                root /var/www/certbot;
            }

            # Redirect all other traffic to HTTPS
            location / {
                return 301 https://$host$request_uri;
            }
        }

        # HTTPS server
        server {
            listen 443 ssl http2;
            server_name archibaldblackant.it www.archibaldblackant.it;

            # SSL certificates (Let's Encrypt)
            ssl_certificate /etc/nginx/ssl/fullchain.pem;
            ssl_certificate_key /etc/nginx/ssl/privkey.pem;
            ssl_dhparam /etc/nginx/dhparam.pem;

            # Security headers
            add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
            add_header X-Frame-Options "SAMEORIGIN" always;
            add_header X-Content-Type-Options "nosniff" always;
            add_header X-XSS-Protection "1; mode=block" always;

            # Frontend (React PWA)
            location / {
                proxy_pass http://frontend:80;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
            }

            # Backend API
            location /api/ {
                limit_req zone=api_limit burst=20 nodelay;

                proxy_pass http://backend:3000;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;

                # WebSocket support
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection "upgrade";

                # Timeouts for long-running operations
                proxy_read_timeout 120s;
                proxy_connect_timeout 10s;
            }

            # Stricter rate limit for auth endpoints
            location /api/auth/login {
                limit_req zone=login_limit burst=3 nodelay;

                proxy_pass http://backend:3000;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
            }

            # Health check endpoint (no rate limit)
            location /health {
                proxy_pass http://backend:3000;
                access_log off;
            }
        }
    }
    ```

    Create directory structure and generate DH params (will be done on VPS):
    ```bash
    mkdir -p nginx/ssl
    # DH params generation will be done in Task 5 (slow operation, ~2 minutes)
    ```

    Key decisions:
    - SSL termination at Nginx (backend is HTTP-only internally)
    - HSTS header (force HTTPS for 1 year)
    - Security headers (XSS, clickjacking protection)
    - Rate limiting (10 req/s API, 5 req/min login)
    - WebSocket support for real-time progress
    - Separate /api/auth/login limit (brute-force protection)
  </action>
  <verify>
    - [nginx/nginx.conf](nginx/nginx.conf) created
    - HTTP → HTTPS redirect configured
    - SSL certificate paths correct (/etc/nginx/ssl/)
    - Rate limiting configured for /api/ and /api/auth/login
    - WebSocket upgrade headers present
    - Security headers configured (HSTS, X-Frame-Options, etc.)
  </verify>
  <done>
    Nginx reverse proxy configuration created with SSL, rate limiting, and security headers
  </done>
</task>

<task type="checkpoint:human-action" gate="blocking">
  <what>Generate SSL certificates with Certbot on VPS</what>
  <instructions>
    SSH to VPS and generate Let's Encrypt certificates:

    ```bash
    # Install Certbot
    sudo apt install -y certbot

    # Generate DH parameters (takes ~2 minutes)
    sudo openssl dhparam -out /home/deploy/archibald-app/nginx/dhparam.pem 2048

    # Stop any running Nginx (if present)
    docker compose down nginx-proxy 2>/dev/null || true

    # Generate Let's Encrypt certificate (standalone mode)
    sudo certbot certonly --standalone \
      -d archibaldblackant.it \
      -d www.archibaldblackant.it \
      --non-interactive \
      --agree-tos \
      --email <YOUR_EMAIL> \
      --preferred-challenges http

    # Copy certificates to project directory
    sudo mkdir -p /home/deploy/archibald-app/nginx/ssl
    sudo cp /etc/letsencrypt/live/archibaldblackant.it/fullchain.pem /home/deploy/archibald-app/nginx/ssl/
    sudo cp /etc/letsencrypt/live/archibaldblackant.it/privkey.pem /home/deploy/archibald-app/nginx/ssl/
    sudo chown -R deploy:deploy /home/deploy/archibald-app/nginx/ssl
    sudo chmod 600 /home/deploy/archibald-app/nginx/ssl/*.pem

    # Setup auto-renewal cron job
    sudo bash -c 'echo "0 3 * * * certbot renew --quiet --post-hook \"docker compose -f /home/deploy/archibald-app/docker-compose.yml restart nginx-proxy\"" | crontab -'
    ```

    Verify:
    - Certificates generated in `/etc/letsencrypt/live/archibaldblackant.it/`
    - Certificates copied to `~/archibald-app/nginx/ssl/`
    - DH params generated at `~/archibald-app/nginx/dhparam.pem`
    - Cron job added for auto-renewal (runs daily at 3 AM)
  </instructions>
  <resume-signal>Confirm: SSL certificates generated and copied, auto-renewal configured</resume-signal>
</task>

<task type="checkpoint:human-action" gate="blocking">
  <what>Create production .env file with real credentials on VPS</what>
  <instructions>
    SSH to VPS and create `.env` file in `~/archibald-app/`:

    ```bash
    cd ~/archibald-app

    # Copy template
    cp .env.example .env

    # Edit with real values (use nano, vim, or generate programmatically)
    nano .env
    ```

    Fill in:
    ```env
    # Database
    DATABASE_PATH=/app/data

    # JWT Secret (generate with: openssl rand -base64 32)
    JWT_SECRET=<GENERATE_32_BYTE_SECRET>

    # Redis
    REDIS_HOST=redis
    REDIS_PORT=6379

    # Puppeteer
    PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser

    # Archibald ERP (SENSITIVE - NEVER COMMIT)
    ARCHIBALD_BASE_URL=https://4.231.124.90/Archibald
    ARCHIBALD_USERNAME=<PRODUCTION_USERNAME>
    ARCHIBALD_PASSWORD=<PRODUCTION_PASSWORD>
    ```

    Security:
    - `.env` file must be readable only by deploy user: `chmod 600 .env`
    - Verify not in git: `git check-ignore .env` should return `.env`
    - Double-check `.gitignore` includes `.env`

    CRITICAL: Never commit .env to git. Credentials stay on VPS only.
  </instructions>
  <resume-signal>Confirm: .env file created with production credentials, permissions set to 600</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Backend Dockerfile created with Chromium bundled
- [ ] Frontend Dockerfile created with Nginx serve
- [ ] docker-compose.yml created with all 4 services
- [ ] Nginx reverse proxy config created with SSL
- [ ] DH parameters generated on VPS
- [ ] Let's Encrypt SSL certificates generated
- [ ] Auto-renewal cron job configured
- [ ] Production .env file created on VPS (not in git)
- [ ] All files have proper permissions (SSL certs 600, .env 600)
</verification>

<success_criteria>

- All tasks completed
- Docker orchestration ready
- SSL certificates valid and auto-renewing
- Secrets secured (not in git)
- No errors in verification checks
</success_criteria>

<output>
After completion, create `.planning/phases/12-deployment-infrastructure/12-02-SUMMARY.md`
</output>

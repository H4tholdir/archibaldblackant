---
phase: 18-customers-sync-optimization
plan: 01
type: execute
---

<objective>
Profile and analyze customer sync performance to identify bottlenecks and optimization opportunities.

Purpose: Establish baseline performance metrics for CustomerSyncService and document bottlenecks for subsequent optimization.
Output: Performance analysis report with execution times, bottleneck identification, and optimization recommendations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Key files:**
@archibald-web-app/backend/src/customer-sync-service.ts
@archibald-web-app/backend/src/archibald-bot.ts
@archibald-web-app/backend/src/customer-db.ts

**Tech stack available:**
- Puppeteer for browser automation
- SQLite with better-sqlite3
- Winston logger for timing logs
- TypeScript strict mode

**Existing sync implementation:**
- CustomerSyncService.syncCustomers() method (~1128 lines total file)
- Pagination through customer list pages
- Checkpoint resume capability
- Filter clearing and page navigation
- Per-customer data extraction

**Performance considerations:**
- Puppeteer wait times (waitForSelector, explicit setTimeout)
- Page navigation overhead (goto, network idle)
- Filter clearing operations
- Database insert batch operations
- Total sync time for all customers

**Profiling approach:**
- Add timestamp logging at key points
- Measure: total sync time, per-page time, per-customer time, navigation overhead
- Use console.time/timeEnd or logger with timestamps
- Run full sync and collect metrics
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add performance profiling instrumentation to syncCustomers</name>
  <files>
    archibald-web-app/backend/src/customer-sync-service.ts
  </files>
  <action>
    Add timing logs throughout syncCustomers method to measure performance:

    1. At start of method (after line 175):
    ```typescript
    const syncStartTime = Date.now();
    logger.info('⏱️ [PERF] Customer sync started', { startTime: syncStartTime });
    ```

    2. After login (around line 201):
    ```typescript
    const loginEndTime = Date.now();
    logger.info('⏱️ [PERF] Login completed', {
      duration: loginEndTime - syncStartTime,
      elapsed: `${((loginEndTime - syncStartTime) / 1000).toFixed(2)}s`
    });
    ```

    3. After navigation to customer list (around line 226):
    ```typescript
    const navEndTime = Date.now();
    logger.info('⏱️ [PERF] Navigation to customer list completed', {
      duration: navEndTime - loginEndTime,
      elapsed: `${((navEndTime - loginEndTime) / 1000).toFixed(2)}s`
    });
    ```

    4. After filter clearing (around line 254):
    ```typescript
    const filterEndTime = Date.now();
    logger.info('⏱️ [PERF] Filter clearing completed', {
      duration: filterEndTime - navEndTime,
      elapsed: `${((filterEndTime - navEndTime) / 1000).toFixed(2)}s`
    });
    ```

    5. Inside pagination loop (start of each page):
    ```typescript
    const pageStartTime = Date.now();
    logger.info('⏱️ [PERF] Processing page started', {
      page: currentPage,
      timestamp: pageStartTime
    });
    ```

    6. After scraping customers on page (end of page processing):
    ```typescript
    const pageEndTime = Date.now();
    const customersOnPage = customers.length; // Assuming customers array from scraping
    logger.info('⏱️ [PERF] Page processing completed', {
      page: currentPage,
      customersCount: customersOnPage,
      duration: pageEndTime - pageStartTime,
      elapsed: `${((pageEndTime - pageStartTime) / 1000).toFixed(2)}s`,
      avgPerCustomer: customersOnPage > 0 ? `${((pageEndTime - pageStartTime) / customersOnPage).toFixed(0)}ms` : 'N/A'
    });
    ```

    7. At end of sync (finally block or completion):
    ```typescript
    const syncEndTime = Date.now();
    const totalDuration = syncEndTime - syncStartTime;
    logger.info('⏱️ [PERF] Customer sync completed', {
      totalDuration,
      elapsed: `${(totalDuration / 1000).toFixed(2)}s`,
      pagesProcessed: currentPage,
      customersProcessed: this.progress.customersProcessed,
      avgPerPage: currentPage > 0 ? `${(totalDuration / currentPage / 1000).toFixed(2)}s` : 'N/A',
      avgPerCustomer: this.progress.customersProcessed > 0 ? `${(totalDuration / this.progress.customersProcessed).toFixed(0)}ms` : 'N/A'
    });
    ```

    Why detailed timing: Identifies specific bottlenecks (login, navigation, filter, scraping, page transitions) for targeted optimization.
  </action>
  <verify>
    npm run typecheck in backend directory passes

    Manual check:
    1. Start backend: cd archibald-web-app/backend && npm run dev
    2. Trigger customer sync (via API or auto-sync)
    3. Check logs for [PERF] entries
    4. Verify timestamps and duration calculations are correct
  </verify>
  <done>
    Performance profiling instrumentation added to syncCustomers.
    Timing logs at 7 key points: start, login, navigation, filter clearing, per-page start/end, completion.
    Duration calculations for each phase.
    TypeScript compilation passes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Run profiled sync and collect performance data</name>
  <files>
    .planning/phases/18-customers-sync-optimization/PERF-DATA.json
  </files>
  <action>
    Execute profiled customer sync and capture performance metrics:

    1. Ensure backend is running with profiling instrumentation
    2. Trigger full customer sync (force sync to bypass recent sync check)
    3. Monitor logs and collect timing data
    4. Create PERF-DATA.json with collected metrics:

    ```json
    {
      "testDate": "2026-01-18T...",
      "totalCustomers": 150,
      "totalPages": 5,
      "phases": {
        "login": { "duration": 8500, "elapsed": "8.50s" },
        "navigation": { "duration": 3200, "elapsed": "3.20s" },
        "filterClearing": { "duration": 2500, "elapsed": "2.50s" },
        "scraping": { "duration": 45000, "elapsed": "45.00s" }
      },
      "pageMetrics": [
        { "page": 1, "customers": 30, "duration": 9200, "avgPerCustomer": "307ms" },
        { "page": 2, "customers": 30, "duration": 8800, "avgPerCustomer": "293ms" }
      ],
      "totals": {
        "totalDuration": 59200,
        "elapsed": "59.20s",
        "avgPerPage": "11.84s",
        "avgPerCustomer": "395ms"
      },
      "bottlenecks": [
        "Filter clearing takes 2.5s (4.2% of total) - potentially skippable",
        "Page navigation overhead ~1-2s per page",
        "Per-customer scraping averages 395ms"
      ]
    }
    ```

    Use actual values from log output. If sync takes too long or fails, document the issue.

    Why JSON format: Structured data enables programmatic analysis, comparison with future optimizations.
  </action>
  <verify>
    Manual check:
    1. Verify PERF-DATA.json exists with real timing data
    2. Check bottlenecks section identifies slowest operations
    3. Ensure metrics match log output
  </verify>
  <done>
    PERF-DATA.json created with baseline performance metrics.
    All timing phases documented with durations.
    Bottlenecks identified from profiling data.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create performance analysis report</name>
  <files>
    .planning/phases/18-customers-sync-optimization/ANALYSIS.md
  </files>
  <action>
    Create comprehensive performance analysis report:

    ```markdown
    # Customer Sync Performance Analysis

    **Date**: 2026-01-18
    **File**: customer-sync-service.ts
    **Method**: syncCustomers()

    ## Baseline Metrics

    | Metric | Value |
    |--------|-------|
    | Total customers | 150 |
    | Total pages | 5 |
    | Total duration | 59.20s |
    | Avg per page | 11.84s |
    | Avg per customer | 395ms |

    ## Phase Breakdown

    | Phase | Duration | % of Total | Notes |
    |-------|----------|-----------|-------|
    | Login | 8.50s | 14.4% | First-time browser initialization |
    | Navigation | 3.20s | 5.4% | Navigate to customer list page |
    | Filter clearing | 2.50s | 4.2% | Clear search filters (potentially unnecessary) |
    | Scraping | 45.00s | 76.0% | Main data extraction loop |

    ## Bottlenecks Identified

    ### 1. Filter Clearing (2.5s, 4.2%)
    - **Location**: Lines 234-253
    - **Operation**: Clears all search input filters
    - **Issue**: May be unnecessary if no filters were applied
    - **Recommendation**: Skip if no active filters detected, or remove entirely if not used

    ### 2. Page Navigation Overhead (~1-2s per page)
    - **Location**: Pagination loop
    - **Operation**: Click next page, wait for load
    - **Issue**: Network idle waits may be longer than needed
    - **Recommendation**: Use faster wait conditions (specific selectors vs networkidle2)

    ### 3. Per-Customer Scraping (395ms avg)
    - **Location**: Customer data extraction loop
    - **Operation**: Parse table rows, extract fields
    - **Issue**: Sequential processing, multiple DOM queries per customer
    - **Recommendation**: Batch DOM queries, parallel processing if feasible

    ### 4. Explicit setTimeout Delays
    - **Location**: Multiple locations (3s, 2s waits)
    - **Operation**: Fixed delay waits for page load
    - **Issue**: Conservative waits add unnecessary time
    - **Recommendation**: Replace with dynamic waitForSelector conditions

    ## Optimization Opportunities

    ### High Impact (>5s potential savings)
    1. **Remove/optimize filter clearing**: -2.5s (if unnecessary)
    2. **Optimize page navigation waits**: -5-10s (replace networkidle2 with specific selectors)
    3. **Reduce explicit setTimeout delays**: -10-15s (replace with dynamic waits)

    ### Medium Impact (1-5s potential savings)
    4. **Batch customer data extraction**: -3-5s (single DOM query for all customers)
    5. **Optimize login caching**: -2-3s (reuse authenticated browser if recent)

    ### Low Impact (<1s potential savings)
    6. **Database batch inserts**: -0.5-1s (already batched, limited improvement)

    ## Estimated Optimization Potential

    | Scenario | Current | Optimized | Improvement |
    |----------|---------|-----------|-------------|
    | Conservative | 59.2s | 42s | -17.2s (-29%) |
    | Moderate | 59.2s | 35s | -24.2s (-41%) |
    | Aggressive | 59.2s | 28s | -31.2s (-53%) |

    ## Next Steps

    1. **Phase 18-02**: Enhance background sync with intelligent scheduling
    2. **Phase 18-03**: Implement incremental sync (delta only)
    3. **Phase 18-05**: Apply identified optimizations
       - Remove unnecessary filter clearing
       - Replace networkidle2 with specific selectors
       - Replace setTimeout with dynamic waitForSelector
       - Batch customer data extraction

    ## Notes

    - Performance varies by network conditions and Archibald server response time
    - Metrics collected on localhost development environment
    - Production performance may differ (VPS network, server load)
    ```

    Adjust values based on actual PERF-DATA.json results. Include all identified bottlenecks and recommendations.

    Why detailed analysis: Provides clear roadmap for optimization efforts, prioritizes high-impact changes.
  </action>
  <verify>
    Manual check:
    1. Verify ANALYSIS.md exists with complete report
    2. Check bottlenecks match PERF-DATA.json findings
    3. Ensure optimization recommendations are actionable
  </verify>
  <done>
    ANALYSIS.md created with comprehensive performance report.
    Baseline metrics documented.
    Bottlenecks identified with specific line numbers.
    Optimization opportunities prioritized by impact.
    Next steps defined for subsequent plans.
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run typecheck` passes in backend directory
- [ ] Performance profiling instrumentation added to syncCustomers
- [ ] PERF-DATA.json created with real timing metrics
- [ ] ANALYSIS.md created with bottleneck analysis and recommendations
- [ ] No TypeScript errors
- [ ] Profiling logs appear in backend logs during sync
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Performance profiling instrumentation functional
- Baseline metrics collected and documented
- Bottlenecks identified with specific locations
- Optimization opportunities prioritized by impact
- Analysis report provides clear roadmap for optimization
- No errors or warnings introduced
  </success_criteria>

<output>
After completion, create `.planning/phases/18-customers-sync-optimization/18-01-SUMMARY.md`:

# Phase 18 Plan 01: Customer Sync Performance Analysis Summary

**[Substantive one-liner - what shipped, not "phase complete"]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `archibald-web-app/backend/src/customer-sync-service.ts` - Description
- `.planning/phases/18-customers-sync-optimization/PERF-DATA.json` - Description
- `.planning/phases/18-customers-sync-optimization/ANALYSIS.md` - Description

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Step

Ready for 18-02-PLAN.md (Background Sync Enhancement)
</output>

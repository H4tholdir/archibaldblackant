---
dependencies:
  - .planning/phases/11-order-management/11-01-RESEARCH.md
  - .planning/phases/11-order-management/11-02-PLAN.md
  - archibald-web-app/backend/src/order-history-service.ts
  - .planning/phases/10-order-history/10-04-SUMMARY.md
---

# Plan 11-03: Implement DDT and Tracking Number Scraping

<objective>
Scrape DDT (Documenti di Trasporto) and tracking information from Archibald, match to orders, and store in database with clickable courier links.
</objective>

<execution_context>
@~/.claude/get-shit-done/references/checkpoints.md
@~/.claude/get-shit-done/references/tdd.md
@archibald-web-app/backend/src/order-history-service.ts
@.planning/phases/11-order-management/11-01-RESEARCH.md
@.planning/phases/10-order-history/10-04-SUMMARY.md
</execution_context>

<context>
## DDT and Tracking Requirements

From 11-CONTEXT.md:

**DDT Page**: `https://4.231.124.90/Archibald/CUSTPACKINGSLIPJOUR_ListView/`

**Data to Scrape**:
- DDT number (e.g., DDT/26000515)
- Tracking number (e.g., "fedex 445291888246")
- Tracking link (format varies by courier: FedEx, UPS Italia, etc.)
- Delivery date
- Total packages
- Delivery method

**Order Matching**: Match via "ID di vendita" (ORD/26000XXX) and "Conto ordine" (customer ID)

**Reusable Patterns from Phase 10**:
- Header-based column detection (Plan 10-04)
- Text-based element identification
- Pattern-based data extraction
- URL normalization for links
- Graceful error handling for missing data

## Implementation Strategy

**Scraping Approach** (similar to Phase 10-04):
1. Navigate to DDT page with direct URL
2. Detect columns by header text (e.g., "NUMERO DDT", "TRACCIABILITÀ")
3. Iterate rows, extract DDT data
4. Match to orders by order ID
5. Store in database with normalized tracking URLs

**Database Changes**:
- Add DDT fields to orders table (from migration 011 in Plan 11-02):
  - `ddt_number` (string)
  - `tracking_number` (string)
  - `tracking_url` (string)
  - `tracking_courier` (string: fedex, ups, etc.)

**Scope**:
- Only orders from **last 3 weeks** (per 11-CONTEXT.md requirements)
- Reduces data volume and focuses on active orders
- Cache strategy: 2-hour TTL (reuse Phase 10 pattern)

## Out of Scope

- Invoice scraping (Plan 11-06)
- Status tracking sync (Plan 11-04)
- UI components (Plan 11-05)
</context>

<tasks>
## Task 1: Database Schema Extension (type: auto)

**Goal**: Add DDT and tracking fields to orders table.

**Actions**:
1. Update migration `archibald-web-app/backend/migrations/011-order-management.sql` (created in Plan 11-02)
2. Add columns:
   ```sql
   ALTER TABLE orders ADD COLUMN ddt_number TEXT;
   ALTER TABLE orders ADD COLUMN tracking_number TEXT;
   ALTER TABLE orders ADD COLUMN tracking_url TEXT;
   ALTER TABLE orders ADD COLUMN tracking_courier TEXT;
   ```
3. Update TypeScript interface in `archibald-web-app/backend/src/order-db.ts`:
   ```typescript
   interface Order {
     // ... existing fields
     ddtNumber?: string;
     trackingNumber?: string;
     trackingUrl?: string;
     trackingCourier?: string;
   }
   ```
4. Run migration against test database
5. Verify columns added with `PRAGMA table_info(orders)`

**Acceptance**:
- Migration updated with DDT/tracking columns
- TypeScript types updated
- Columns visible in database schema

## Task 2: Implement DDT Scraper (type: auto)

**Goal**: Create service to scrape DDT page and extract tracking data.

**Actions**:
1. Create `archibald-web-app/backend/src/ddt-scraper-service.ts`
2. Implement `DDTScraperService` class with method:
   ```typescript
   async scrapeDDTData(username: string, password: string): Promise<DDTData[]>
   ```
3. Service workflow:
   - Acquire BrowserContext from BrowserPool
   - Navigate to DDT page: `https://4.231.124.90/Archibald/CUSTPACKINGSLIPJOUR_ListView/`
   - Wait for table to load
   - **Detect columns by header text** (reuse Phase 10-04 pattern):
     - "NUMERO DDT" → DDT number column
     - "TRACCIABILITÀ" → tracking number column
     - "ID DI VENDITA" → order ID column
     - "DATA DI CONSEGNA" → delivery date column
     - "MODALITÀ DI CONSEGNA" → courier column
   - Iterate table rows:
     - Extract DDT number (e.g., "DDT/26000515")
     - Extract tracking number (e.g., "fedex 445291888246")
     - Extract tracking URL (if clickable link exists)
     - Extract order ID (e.g., "ORD/26000552")
     - Extract delivery date (parse to ISO 8601)
     - Extract courier (normalize to lowercase: "fedex", "ups", "dhl")
   - **Handle pagination** (if present, similar to Phase 10-02):
     - Click "Next" button until no more pages
     - Duplicate detection to prevent re-processing
   - Return array of DDT data objects
4. **URL normalization** (Phase 10-04 pattern):
   - If tracking URL is relative, prepend Archibald base URL
   - If no URL found, construct from courier + tracking number:
     - FedEx: `https://www.fedex.com/fedextrack/?tracknumbers={number}`
     - UPS: `https://www.ups.com/track?tracknum={number}`
     - DHL: `https://www.dhl.com/en/express/tracking.html?AWB={number}`
5. Error handling:
   - Missing columns → log warning, return partial data
   - Pagination timeout → log error, return data scraped so far
   - Network error → retry once, then fail gracefully

**Acceptance**:
- `DDTScraperService` class created
- Column detection by header text (robust to order changes)
- Pagination handled correctly
- Tracking URLs normalized and courier-specific
- Comprehensive error handling and logging

## Task 3: Implement Order Matching Logic (type: auto)

**Goal**: Match DDT data to orders in database by order ID.

**Actions**:
1. Add method to `DDTScraperService`:
   ```typescript
   async syncDDTToOrders(ddtData: DDTData[]): Promise<SyncResult>
   ```
2. Matching logic:
   - For each DDT entry:
     - Extract order ID (e.g., "ORD/26000552")
     - Query database for order with matching `archibaldOrderId` field
     - If found:
       - Update order with DDT data (number, tracking, URL, courier)
       - Log successful match
     - If not found:
       - Log warning (order not in our database)
   - Return sync result: `{ matched: number, notFound: number }`
3. Handle edge cases:
   - Multiple DDTs per order (keep most recent)
   - Missing order ID (skip, log warning)
   - Invalid tracking data (store as-is, log warning)
4. **Transactional update**:
   - Use database transaction for atomic updates
   - Rollback on error

**Acceptance**:
- Matching by order ID works reliably
- Database updates atomic (transaction)
- Edge cases handled gracefully
- Sync result provides transparency

## Task 4: Create API Endpoint (type: auto)

**Goal**: Add endpoint to trigger DDT sync on-demand.

**Actions**:
1. Add endpoint to `archibald-web-app/backend/src/index.ts`:
   ```typescript
   POST /api/orders/sync-ddt
   ```
2. Endpoint logic:
   - Extract JWT from request (requireAuth middleware)
   - Fetch user credentials (CredentialStore or from request)
   - Pause background services (PriorityManager)
   - Call `DDTScraperService.scrapeDDTData()`
   - Call `DDTScraperService.syncDDTToOrders()`
   - Resume background services
   - Return sync result with counts
3. Response format:
   ```typescript
   {
     success: boolean;
     message: string;
     matched: number;
     notFound: number;
     scrapedCount: number;
   }
   ```
4. Add rate limiting (max 1 sync per 2 hours per user)
5. Cache result for 2 hours (reuse Phase 10 cache pattern)

**Acceptance**:
- Endpoint registered and authenticated
- PriorityManager integration for bot safety
- Rate limiting prevents excessive scraping
- Cache reduces Archibald load
- Detailed sync result returned

## Task 5: Write Unit Tests (type: auto)

**Goal**: TDD test coverage for DDTScraperService.

**Actions**:
1. Create `archibald-web-app/backend/src/ddt-scraper-service.spec.ts`
2. Test cases:
   - **Column detection**: Verify header-based column mapping
   - **Data extraction**: Parse DDT entry correctly
   - **URL normalization**: Relative URLs converted to absolute
   - **Courier detection**: Normalize courier names (FedEx, UPS, DHL)
   - **Order matching**: Match DDT to order by ID
   - **Edge cases**: Missing columns, pagination, missing order ID
3. Mock Puppeteer page interactions
4. Mock database queries
5. Run tests: `npm test ddt-scraper-service.spec.ts`

**Acceptance**:
- 6+ test cases covering main scenarios
- All tests passing
- Column detection robust to table changes
- Test coverage > 80%

## Task 6: Integration Test (type: checkpoint:human-verify)

**Goal**: Test full DDT scraping workflow with real Archibald session.

**Actions**:
1. Ensure test order(s) exist with known DDT data in Archibald
2. Start backend server
3. Make API request:
   ```bash
   curl -X POST http://localhost:3000/api/orders/sync-ddt \
     -H "Authorization: Bearer $JWT" \
     -H "Content-Type: application/json"
   ```
4. Observe:
   - Backend logs (scraping steps, matches found)
   - Puppeteer browser (DDT page navigation)
   - Database updates (tracking data stored)
5. Verify in database:
   - Orders have `ddt_number`, `tracking_number`, `tracking_url`, `tracking_courier`
   - Tracking URLs are clickable and correct
6. Test cache:
   - Second request within 2 hours should return cached result (no scraping)

**Acceptance**:
- Real DDT data scraped successfully
- Orders matched by ID
- Tracking URLs stored and normalized
- Cache works correctly (2-hour TTL)
- No errors in backend logs

**Checkpoint**: User must verify that DDT data exists for test orders in Archibald.

</tasks>

<verification>
## Success Criteria

- [ ] Database migration adds DDT/tracking columns
- [ ] DDTScraperService scrapes DDT page successfully
- [ ] Column detection by header text (robust)
- [ ] Order matching by ID works reliably
- [ ] Tracking URLs normalized per courier
- [ ] API endpoint with 2-hour cache
- [ ] Unit tests cover main scenarios (80%+ coverage)
- [ ] Integration test scrapes real data
- [ ] Cache prevents excessive scraping

## Verification Steps

1. Run database migration and verify schema changes
2. Run unit tests: `npm test ddt-scraper-service.spec.ts`
3. Run integration test with real Archibald session
4. Verify tracking data in database for test orders
5. Test cache by making second request
6. Click tracking URL in database → opens courier website
</verification>

<success_criteria>
DDT and tracking scraping complete, tested, and integrated with database. Tracking URLs clickable and courier-specific.
</success_criteria>

<output>
- Updated `archibald-web-app/backend/migrations/011-order-management.sql` - DDT/tracking columns
- `archibald-web-app/backend/src/ddt-scraper-service.ts` - DDT scraping service
- `archibald-web-app/backend/src/ddt-scraper-service.spec.ts` - Unit tests
- Updated `archibald-web-app/backend/src/index.ts` - Sync DDT endpoint
- Updated `archibald-web-app/backend/src/order-db.ts` - Type definitions
- `.planning/phases/11-order-management/11-03-SUMMARY.md` - Implementation summary
</output>

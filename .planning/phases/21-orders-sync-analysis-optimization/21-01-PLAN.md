---
phase: 21-orders-sync-analysis-optimization
plan: 01
title: Orders PDF Parser & Separate Database
subsystem: integration
complexity: high
estimated_duration: 90min
tags: [python, pdf-parsing, node-js, orders, 7-page-cycle, italian-locale, database-migration]
---

# Plan 21-01: Orders PDF Parser & Separate Database

## Objective

Create Python PDF parser for orders with **7-page cycle support** (verified from discovery), Italian date/currency format handling, separate `orders.db` database, and Node.js wrapper via child_process.spawn - following Phase 18/19/20 proven patterns.

## Execution Context

**Discovery Results (PDF-ANALYSIS-RESULTS.md):**
- ✅ Ordini.pdf has **7-page cycle pattern**
- ✅ 280 pages = ~40 orders
- ✅ Table-based format (~25 rows per page)
- ✅ All 20 columns from SALESTABLE_ListView_Agent confirmed
- ✅ Italian locale: "DD/MM/YYYY HH:MM:SS", "105,60 €", "21,49 %"

**Page Cycle Structure:**
- Page 1/7: Order ID, Customer (4 cols)
- Page 2/7: Delivery info (2 cols)
- Page 3/7: Dates (3 cols)
- Page 4/7: Status fields (4 cols)
- Page 5/7: Transfer info (3 cols)
- Page 6/7: Amounts (4 cols)
- Page 7/7: Total + gift flag (2 cols)

**Phase 18/19/20 Proven Patterns:**
- Python PDF parser with multi-page cycle handling
- Node.js wrapper via `child_process.spawn` (NOT exec)
- Type-safe TypeScript interfaces matching Python dataclasses
- Health check endpoints for deployment verification
- Italian locale forcing for date/currency parsing
- 20MB buffer management for large PDFs
- 300s timeout (orders PDF is large: 280 pages)
- Streaming extraction for RAM optimization (<100MB)

**Separate Database Pattern (from Phase 20 - Prices):**
- Create dedicated `orders.db` (separate from existing multi-table orders.db)
- MD5 hash delta detection
- Simplified schema focused on PDF fields only
- Clean separation: orders.db, ddt.db, invoices.db (3 databases)

## Context

**Current State:**
- Existing `orders.db` has complex schema with DDT + Invoice fields mixed
- HTML scraping via OrderHistoryService (Phase 10)
- No delta detection → full scraping every sync
- Per-user data isolation

**Migration Strategy:**
- **NEW:** Create `orders.db` with PDF-based schema (20 fields)
- **LATER (Plan 21-02):** Create `ddt.db` for DDT data
- **LATER (Plan 21-03):** Create `invoices.db` for invoice data
- **LATER (Plan 21-04):** Migrate existing data or deprecate old schema

**Goals:**
1. Parse Ordini.pdf with 7-page cycle logic
2. Extract all 20 fields per order
3. Handle Italian date/currency formats
4. Create separate orders.db with delta detection
5. Node.js service wrapper with health check
6. Performance target: < 90s for ~40 orders

## Tasks

### Task 1: Python PDF Parser for Orders (7-Page Cycle) (35min)

**Goal:** Create Python script to parse Ordini.pdf with 7-page cycle logic.

**Deliverables:**

1. **`scripts/parse-orders-pdf.py`** - Python parser with dataclasses
   - Dataclass `ParsedOrder` matching 20 PDF fields
   - Italian date parser: "DD/MM/YYYY HH:MM:SS" → ISO 8601
   - Italian currency parser: "105,60 €" → string (preserve format)
   - Italian percentage parser: "21,49 %" → float
   - 7-page cycle processor with streaming
   - JSON output to stdout (one order per line)

**Implementation:**
```python
#!/usr/bin/env python3
"""
Parse Ordini.pdf - 7-page cycle structure
Outputs JSON to stdout (one order per line)
"""

import pdfplumber
import json
import sys
import re
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Optional

@dataclass
class ParsedOrder:
    """Order data from Ordini.pdf - 20 fields"""
    # Page 1/7: Order Identification
    id: str  # Internal ID (e.g., "70.962")
    order_number: str  # e.g., "ORD/26000887"
    customer_profile_id: str  # e.g., "1002241"
    customer_name: str  # e.g., "Carrazza Giovanni"

    # Page 2/7: Delivery
    delivery_name: Optional[str]
    delivery_address: Optional[str]

    # Page 3/7: Dates
    creation_date: str  # ISO 8601
    delivery_date: Optional[str]  # ISO 8601
    remaining_sales_financial: Optional[str]

    # Page 4/7: Status
    customer_reference: Optional[str]
    sales_status: Optional[str]  # "Ordine aperto", "Consegnato"
    order_type: Optional[str]  # "Ordine di vendita"
    document_status: Optional[str]  # "Nessuno", "Documento di trasporto"

    # Page 5/7: Transfer
    sales_origin: Optional[str]  # "Agent"
    transfer_status: Optional[str]  # "Trasferito"
    transfer_date: Optional[str]  # ISO 8601

    # Page 6/7: Amounts
    completion_date: Optional[str]  # ISO 8601
    discount_percent: Optional[str]  # Keep as string for precision
    gross_amount: Optional[str]  # Italian format: "105,60 €"

    # Page 7/7: Total
    total_amount: Optional[str]  # Italian format: "82,91 €"


def parse_italian_datetime(date_str: str) -> Optional[str]:
    """Parse Italian datetime to ISO 8601: DD/MM/YYYY HH:MM:SS → YYYY-MM-DDTHH:MM:SS"""
    if not date_str or date_str.strip() == "":
        return None
    try:
        # Format: "20/01/2026 12:04:22"
        dt = datetime.strptime(date_str.strip(), "%d/%m/%Y %H:%M:%S")
        return dt.isoformat()
    except ValueError:
        return None


def parse_italian_date(date_str: str) -> Optional[str]:
    """Parse Italian date to ISO 8601: DD/MM/YYYY → YYYY-MM-DD"""
    if not date_str or date_str.strip() == "":
        return None
    try:
        # Format: "21/01/2026"
        dt = datetime.strptime(date_str.strip(), "%d/%m/%Y")
        return dt.date().isoformat()
    except ValueError:
        return None


def normalize_multiline(text: Optional[str]) -> Optional[str]:
    """Normalize multiline text (e.g., addresses) to single line"""
    if not text:
        return None
    # Replace newlines with comma-space
    return re.sub(r'\s+', ' ', text.strip())


def parse_orders_pdf(pdf_path: str):
    """
    Parse Ordini.pdf with 7-page cycle structure.
    Yields one ParsedOrder per order.
    """
    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)

        # Process in 7-page cycles
        for cycle_start in range(0, total_pages, 7):
            # Extract all 7 pages as tables
            tables = []
            for i in range(7):
                page_idx = cycle_start + i
                if page_idx >= total_pages:
                    break

                page = pdf.pages[page_idx]
                page_tables = page.extract_tables()

                if not page_tables or not page_tables[0]:
                    # Skip if no table found
                    tables.append([])
                else:
                    tables.append(page_tables[0])

                # Free memory
                page = None

            # Need all 7 pages for complete cycle
            if len(tables) < 7:
                break

            # Skip if tables are empty
            if not tables[0] or len(tables[0]) <= 1:  # Header only
                continue

            # Combine rows (row N = same order across all 7 pages)
            num_rows = len(tables[0])

            for row_idx in range(1, num_rows):  # Skip header (row 0)
                # Extract fields from each page
                try:
                    # Page 1/7: Order ID (4 columns)
                    row1 = tables[0][row_idx] if row_idx < len(tables[0]) else [None] * 4
                    order_id = row1[0] if len(row1) > 0 else None
                    order_number = row1[1] if len(row1) > 1 else None
                    customer_profile_id = row1[2] if len(row1) > 2 else None
                    customer_name = row1[3] if len(row1) > 3 else None

                    # Skip if no order ID
                    if not order_id or not order_number:
                        continue

                    # Skip garbage rows (ID = "0" pattern from other PDFs)
                    if order_id == "0" or order_number == "0":
                        continue

                    # Page 2/7: Delivery (2 columns)
                    row2 = tables[1][row_idx] if row_idx < len(tables[1]) else [None] * 2
                    delivery_name = row2[0] if len(row2) > 0 else None
                    delivery_address = normalize_multiline(row2[1]) if len(row2) > 1 else None

                    # Page 3/7: Dates (3 columns)
                    row3 = tables[2][row_idx] if row_idx < len(tables[2]) else [None] * 3
                    creation_date = parse_italian_datetime(row3[0]) if len(row3) > 0 else None
                    delivery_date = parse_italian_date(row3[1]) if len(row3) > 1 else None
                    remaining_sales_financial = row3[2] if len(row3) > 2 else None

                    # Page 4/7: Status (4 columns)
                    row4 = tables[3][row_idx] if row_idx < len(tables[3]) else [None] * 4
                    customer_reference = row4[0] if len(row4) > 0 else None
                    sales_status = row4[1] if len(row4) > 1 else None
                    order_type = row4[2] if len(row4) > 2 else None
                    document_status = row4[3] if len(row4) > 3 else None

                    # Page 5/7: Transfer (3 columns)
                    row5 = tables[4][row_idx] if row_idx < len(tables[4]) else [None] * 3
                    sales_origin = row5[0] if len(row5) > 0 else None
                    transfer_status = row5[1] if len(row5) > 1 else None
                    transfer_date = parse_italian_date(row5[2]) if len(row5) > 2 else None

                    # Page 6/7: Amounts (4 columns)
                    row6 = tables[5][row_idx] if row_idx < len(tables[5]) else [None] * 4
                    completion_date = parse_italian_date(row6[0]) if len(row6) > 0 else None
                    # Skip row6[1] = "Preventivo" (always "No")
                    discount_percent = row6[2] if len(row6) > 2 else None
                    gross_amount = row6[3] if len(row6) > 3 else None

                    # Page 7/7: Total (2 columns)
                    row7 = tables[6][row_idx] if row_idx < len(tables[6]) else [None] * 2
                    total_amount = row7[0] if len(row7) > 0 else None
                    # Skip row7[1] = "ORDINE OMAGGIO" (gift flag)

                    # Create ParsedOrder
                    order = ParsedOrder(
                        id=order_id,
                        order_number=order_number,
                        customer_profile_id=customer_profile_id,
                        customer_name=customer_name,
                        delivery_name=delivery_name,
                        delivery_address=delivery_address,
                        creation_date=creation_date,
                        delivery_date=delivery_date,
                        remaining_sales_financial=remaining_sales_financial,
                        customer_reference=customer_reference,
                        sales_status=sales_status,
                        order_type=order_type,
                        document_status=document_status,
                        sales_origin=sales_origin,
                        transfer_status=transfer_status,
                        transfer_date=transfer_date,
                        completion_date=completion_date,
                        discount_percent=discount_percent,
                        gross_amount=gross_amount,
                        total_amount=total_amount
                    )

                    yield order

                except Exception as e:
                    # Skip malformed rows
                    print(f"Warning: Error parsing row {row_idx} in cycle {cycle_start}: {e}", file=sys.stderr)
                    continue

            # Free tables memory
            tables = None


def main():
    """Main entry point - outputs JSON to stdout"""
    if len(sys.argv) < 2:
        print("Usage: parse-orders-pdf.py <pdf_path>", file=sys.stderr)
        sys.exit(1)

    pdf_path = sys.argv[1]

    try:
        for order in parse_orders_pdf(pdf_path):
            # Output one JSON object per line
            print(json.dumps(asdict(order), ensure_ascii=False))

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
```

**Success Criteria:**
- [x] Parser extracts all 20 fields correctly
- [x] Italian dates converted to ISO 8601
- [x] Italian currency preserved as strings
- [x] Multiline addresses normalized
- [x] Streaming output (one JSON per line)
- [x] Memory efficient (processes one cycle at a time)

---

### Task 2: Separate Orders Database Creation (25min)

**Goal:** Create new `orders.db` database with simplified PDF-based schema.

**Deliverables:**

1. **`src/order-db-new.ts`** - New OrderDatabase class (will replace old one later)
   - Singleton pattern
   - MD5 hash delta detection
   - Schema focused on 20 PDF fields
   - Upsert method with insert/update/skip logic
   - Stats methods (total count, last sync time)

**Database Schema:**
```sql
CREATE TABLE orders (
  id TEXT PRIMARY KEY,           -- Archibald internal ID (e.g., "70.962")
  user_id TEXT NOT NULL,         -- Multi-tenant support

  -- Page 1/7: Order Identification
  order_number TEXT NOT NULL UNIQUE,  -- ORD/26000887
  customer_profile_id TEXT,
  customer_name TEXT NOT NULL,

  -- Page 2/7: Delivery
  delivery_name TEXT,
  delivery_address TEXT,

  -- Page 3/7: Dates
  creation_date TEXT NOT NULL,   -- ISO 8601
  delivery_date TEXT,
  remaining_sales_financial TEXT,

  -- Page 4/7: Status
  customer_reference TEXT,
  sales_status TEXT,
  order_type TEXT,
  document_status TEXT,

  -- Page 5/7: Transfer
  sales_origin TEXT,
  transfer_status TEXT,
  transfer_date TEXT,

  -- Page 6/7: Amounts
  completion_date TEXT,
  discount_percent TEXT,         -- Keep as string for precision
  gross_amount TEXT,             -- Italian format: "105,60 €"

  -- Page 7/7: Total
  total_amount TEXT,             -- Italian format: "82,91 €"

  -- Sync metadata
  hash TEXT NOT NULL,            -- MD5 of key fields for delta detection
  last_sync INTEGER NOT NULL,    -- Unix timestamp

  created_at TEXT NOT NULL
);

CREATE INDEX idx_orders_user_id ON orders(user_id);
CREATE INDEX idx_orders_number ON orders(order_number);
CREATE INDEX idx_orders_customer ON orders(customer_profile_id);
CREATE INDEX idx_orders_sync ON orders(last_sync);
CREATE INDEX idx_orders_status ON orders(sales_status);
```

**Implementation Pattern (from Phase 20 - PriceDatabase):**
```typescript
import Database from "better-sqlite3";
import crypto from "crypto";
import { logger } from "./logger";
import path from "node:path";

export interface OrderRecord {
  id: string;
  userId: string;
  orderNumber: string;
  customerProfileId: string | null;
  customerName: string;
  deliveryName: string | null;
  deliveryAddress: string | null;
  creationDate: string;  // ISO 8601
  deliveryDate: string | null;
  remainingSalesFinancial: string | null;
  customerReference: string | null;
  salesStatus: string | null;
  orderType: string | null;
  documentStatus: string | null;
  salesOrigin: string | null;
  transferStatus: string | null;
  transferDate: string | null;
  completionDate: string | null;
  discountPercent: string | null;
  grossAmount: string | null;
  totalAmount: string | null;
  lastSync: number;
}

export class OrderDatabaseNew {
  private static instance: OrderDatabaseNew;
  private db: Database.Database;

  private constructor(dbPath?: string) {
    const finalPath = dbPath || path.join(process.cwd(), "data", "orders-new.db");
    this.db = new Database(finalPath);
    this.db.pragma("journal_mode = WAL");
    this.initSchema();
    logger.info("OrderDatabaseNew initialized", { path: finalPath });
  }

  static getInstance(dbPath?: string): OrderDatabaseNew {
    if (!OrderDatabaseNew.instance) {
      OrderDatabaseNew.instance = new OrderDatabaseNew(dbPath);
    }
    return OrderDatabaseNew.instance;
  }

  private initSchema(): void {
    this.db.exec(`
      CREATE TABLE IF NOT EXISTS orders (
        id TEXT PRIMARY KEY,
        user_id TEXT NOT NULL,
        order_number TEXT NOT NULL UNIQUE,
        customer_profile_id TEXT,
        customer_name TEXT NOT NULL,
        delivery_name TEXT,
        delivery_address TEXT,
        creation_date TEXT NOT NULL,
        delivery_date TEXT,
        remaining_sales_financial TEXT,
        customer_reference TEXT,
        sales_status TEXT,
        order_type TEXT,
        document_status TEXT,
        sales_origin TEXT,
        transfer_status TEXT,
        transfer_date TEXT,
        completion_date TEXT,
        discount_percent TEXT,
        gross_amount TEXT,
        total_amount TEXT,
        hash TEXT NOT NULL,
        last_sync INTEGER NOT NULL,
        created_at TEXT NOT NULL
      );

      CREATE INDEX IF NOT EXISTS idx_orders_user_id ON orders(user_id);
      CREATE INDEX IF NOT EXISTS idx_orders_number ON orders(order_number);
      CREATE INDEX IF NOT EXISTS idx_orders_customer ON orders(customer_profile_id);
      CREATE INDEX IF NOT EXISTS idx_orders_sync ON orders(last_sync);
      CREATE INDEX IF NOT EXISTS idx_orders_status ON orders(sales_status);
    `);
  }

  private computeHash(order: Omit<OrderRecord, 'lastSync'>): string {
    // Hash key fields for delta detection
    const hashInput = [
      order.id,
      order.orderNumber,
      order.salesStatus,
      order.documentStatus,
      order.transferStatus,
      order.totalAmount
    ].join('|');
    return crypto.createHash('md5').update(hashInput).digest('hex');
  }

  upsertOrder(userId: string, order: Omit<OrderRecord, 'userId' | 'lastSync'>): 'inserted' | 'updated' | 'skipped' {
    const now = Math.floor(Date.now() / 1000);
    const hash = this.computeHash(order);

    // Check if exists
    const existing = this.db.prepare(`
      SELECT hash FROM orders WHERE user_id = ? AND order_number = ?
    `).get(userId, order.orderNumber) as { hash: string } | undefined;

    if (!existing) {
      // Insert new order
      this.db.prepare(`
        INSERT INTO orders (
          id, user_id, order_number, customer_profile_id, customer_name,
          delivery_name, delivery_address, creation_date, delivery_date,
          remaining_sales_financial, customer_reference, sales_status,
          order_type, document_status, sales_origin, transfer_status,
          transfer_date, completion_date, discount_percent, gross_amount,
          total_amount, hash, last_sync, created_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
      `).run(
        order.id, userId, order.orderNumber, order.customerProfileId, order.customerName,
        order.deliveryName, order.deliveryAddress, order.creationDate, order.deliveryDate,
        order.remainingSalesFinancial, order.customerReference, order.salesStatus,
        order.orderType, order.documentStatus, order.salesOrigin, order.transferStatus,
        order.transferDate, order.completionDate, order.discountPercent, order.grossAmount,
        order.totalAmount, hash, now, new Date().toISOString()
      );
      return 'inserted';
    }

    // Check if changed
    if (existing.hash === hash) {
      // Unchanged - update only last_sync timestamp
      this.db.prepare(`UPDATE orders SET last_sync = ? WHERE user_id = ? AND order_number = ?`)
        .run(now, userId, order.orderNumber);
      return 'skipped';
    }

    // Update changed order
    this.db.prepare(`
      UPDATE orders SET
        customer_profile_id = ?, customer_name = ?, delivery_name = ?,
        delivery_address = ?, creation_date = ?, delivery_date = ?,
        remaining_sales_financial = ?, customer_reference = ?, sales_status = ?,
        order_type = ?, document_status = ?, sales_origin = ?, transfer_status = ?,
        transfer_date = ?, completion_date = ?, discount_percent = ?,
        gross_amount = ?, total_amount = ?, hash = ?, last_sync = ?
      WHERE user_id = ? AND order_number = ?
    `).run(
      order.customerProfileId, order.customerName, order.deliveryName,
      order.deliveryAddress, order.creationDate, order.deliveryDate,
      order.remainingSalesFinancial, order.customerReference, order.salesStatus,
      order.orderType, order.documentStatus, order.salesOrigin, order.transferStatus,
      order.transferDate, order.completionDate, order.discountPercent,
      order.grossAmount, order.totalAmount, hash, now,
      userId, order.orderNumber
    );
    return 'updated';
  }

  getTotalCount(): number {
    const result = this.db.prepare(`SELECT COUNT(*) as count FROM orders`).get() as { count: number };
    return result.count;
  }

  getLastSyncTime(): Date | null {
    const result = this.db.prepare(`
      SELECT MAX(last_sync) as lastSync FROM orders
    `).get() as { lastSync: number | null };

    return result.lastSync ? new Date(result.lastSync * 1000) : null;
  }

  getOrdersByUser(userId: string): OrderRecord[] {
    return this.db.prepare(`
      SELECT * FROM orders WHERE user_id = ? ORDER BY creation_date DESC
    `).all(userId) as OrderRecord[];
  }
}
```

**Success Criteria:**
- [x] Database schema created with all 20 fields
- [x] MD5 hash delta detection functional
- [x] Upsert logic: insert/update/skip correctly
- [x] Indexes created for performance
- [x] Stats methods working

---

### Task 3: Node.js Wrapper Service (20min)

**Goal:** Create Node.js service to execute Python parser via spawn.

**Deliverables:**

1. **`src/pdf-parser-orders-service.ts`** - Service wrapper (singleton pattern)
   - Execute parse-orders-pdf.py via spawn
   - 20MB buffer (PDF is 280 pages)
   - 300s timeout (longer than prices due to more pages)
   - Stream parsing (line-by-line JSON)
   - Type-safe ParsedOrder interface
   - Error handling

**Implementation (from Phase 20 pattern):**
```typescript
import { spawn } from "child_process";
import { logger } from "./logger";
import path from "node:path";

export interface ParsedOrder {
  id: string;
  order_number: string;
  customer_profile_id: string;
  customer_name: string;
  delivery_name: string | null;
  delivery_address: string | null;
  creation_date: string;  // ISO 8601
  delivery_date: string | null;
  remaining_sales_financial: string | null;
  customer_reference: string | null;
  sales_status: string | null;
  order_type: string | null;
  document_status: string | null;
  sales_origin: string | null;
  transfer_status: string | null;
  transfer_date: string | null;
  completion_date: string | null;
  discount_percent: string | null;
  gross_amount: string | null;
  total_amount: string | null;
}

export class PDFParserOrdersService {
  private static instance: PDFParserOrdersService;
  private readonly parserPath: string;
  private readonly timeout: number = 300000; // 5 minutes
  private readonly maxBuffer: number = 20 * 1024 * 1024; // 20MB

  private constructor() {
    this.parserPath = path.join(process.cwd(), "scripts", "parse-orders-pdf.py");
  }

  static getInstance(): PDFParserOrdersService {
    if (!PDFParserOrdersService.instance) {
      PDFParserOrdersService.instance = new PDFParserOrdersService();
    }
    return PDFParserOrdersService.instance;
  }

  async parseOrdersPDF(pdfPath: string): Promise<ParsedOrder[]> {
    logger.info("[PDFParserOrdersService] Starting PDF parsing", { pdfPath });

    return new Promise((resolve, reject) => {
      const startTime = Date.now();
      const orders: ParsedOrder[] = [];
      let stdoutBuffer = "";

      const pythonProcess = spawn("python3", [this.parserPath, pdfPath], {
        maxBuffer: this.maxBuffer,
        timeout: this.timeout,
      });

      // Collect stdout (line-by-line JSON)
      pythonProcess.stdout.on("data", (data: Buffer) => {
        stdoutBuffer += data.toString();

        // Process complete lines
        const lines = stdoutBuffer.split("\n");
        stdoutBuffer = lines.pop() || ""; // Keep incomplete line in buffer

        for (const line of lines) {
          if (line.trim()) {
            try {
              const order = JSON.parse(line) as ParsedOrder;
              orders.push(order);
            } catch (e) {
              logger.warn("[PDFParserOrdersService] Failed to parse line", { line });
            }
          }
        }
      });

      // Log stderr
      pythonProcess.stderr.on("data", (data: Buffer) => {
        logger.warn("[PDFParserOrdersService] Python stderr", { stderr: data.toString() });
      });

      // Handle exit
      pythonProcess.on("close", (code) => {
        const duration = Date.now() - startTime;

        if (code === 0) {
          logger.info("[PDFParserOrdersService] Parsing complete", {
            duration: `${duration}ms`,
            ordersCount: orders.length,
          });
          resolve(orders);
        } else {
          logger.error("[PDFParserOrdersService] Parsing failed", { code, duration: `${duration}ms` });
          reject(new Error(`PDF parsing failed with code ${code}`));
        }
      });

      // Handle timeout
      pythonProcess.on("error", (err) => {
        logger.error("[PDFParserOrdersService] Process error", { error: err.message });
        reject(err);
      });
    });
  }

  isAvailable(): boolean {
    try {
      const fs = require("fs");
      return fs.existsSync(this.parserPath);
    } catch {
      return false;
    }
  }
}
```

**Success Criteria:**
- [x] Service executes Python parser correctly
- [x] Streaming JSON parsing works
- [x] 20MB buffer handles large PDF
- [x] 300s timeout prevents hanging
- [x] Error handling functional

---

### Task 4: Health Check Endpoint (10min)

**Goal:** Add health check for orders PDF parser.

**Deliverables:**

1. **Update `src/index.ts`** - Add `/api/health/pdf-parser-orders` endpoint

**Implementation:**
```typescript
// Add to src/index.ts
app.get("/api/health/pdf-parser-orders", (req, res) => {
  const parserService = PDFParserOrdersService.getInstance();

  const health = {
    available: parserService.isAvailable(),
    parser: "parse-orders-pdf.py",
    timeout: "300s",
    maxBuffer: "20MB",
  };

  if (health.available) {
    res.json({ success: true, ...health });
  } else {
    res.status(503).json({
      success: false,
      message: "Orders PDF parser not available",
      ...health,
    });
  }
});
```

**Success Criteria:**
- [x] Endpoint returns 200 if parser available
- [x] Endpoint returns 503 if parser missing
- [x] Health info includes parser details

---

## Verification

**Unit Tests:**
Create `src/test/order-db-new.test.ts`:
```typescript
import { describe, test, expect, beforeEach, afterEach } from "vitest";
import { OrderDatabaseNew } from "../order-db-new";
import fs from "fs";

describe("OrderDatabaseNew", () => {
  const testDbPath = "/tmp/test-orders-new.db";
  let db: OrderDatabaseNew;

  beforeEach(() => {
    db = OrderDatabaseNew.getInstance(testDbPath);
  });

  afterEach(() => {
    if (fs.existsSync(testDbPath)) {
      fs.unlinkSync(testDbPath);
    }
  });

  test("upsertOrder inserts new order", () => {
    const result = db.upsertOrder("user1", {
      id: "70.962",
      orderNumber: "ORD/26000887",
      customerProfileId: "1002241",
      customerName: "Carrazza Giovanni",
      deliveryName: "Carrazza Giovanni",
      deliveryAddress: "Via Mezzacapo, 121 84036 Sala Consilina Sa",
      creationDate: "2026-01-20T12:04:22",
      deliveryDate: "2026-01-21",
      remainingSalesFinancial: null,
      customerReference: null,
      salesStatus: "Ordine aperto",
      orderType: "Ordine di vendita",
      documentStatus: "Nessuno",
      salesOrigin: "Agent",
      transferStatus: "Trasferito",
      transferDate: "2026-01-20",
      completionDate: "2026-01-20",
      discountPercent: "21,49 %",
      grossAmount: "105,60 €",
      totalAmount: "82,91 €"
    });

    expect(result).toBe("inserted");
  });

  test("upsertOrder skips unchanged order", () => {
    const orderData = {
      id: "70.962",
      orderNumber: "ORD/26000887",
      customerProfileId: "1002241",
      customerName: "Carrazza Giovanni",
      deliveryName: "Carrazza Giovanni",
      deliveryAddress: "Via Mezzacapo, 121",
      creationDate: "2026-01-20T12:04:22",
      deliveryDate: "2026-01-21",
      remainingSalesFinancial: null,
      customerReference: null,
      salesStatus: "Ordine aperto",
      orderType: "Ordine di vendita",
      documentStatus: "Nessuno",
      salesOrigin: "Agent",
      transferStatus: "Trasferito",
      transferDate: "2026-01-20",
      completionDate: "2026-01-20",
      discountPercent: "21,49 %",
      grossAmount: "105,60 €",
      totalAmount: "82,91 €"
    };

    db.upsertOrder("user1", orderData);
    const result = db.upsertOrder("user1", orderData);

    expect(result).toBe("skipped");
  });

  test("upsertOrder updates changed order", () => {
    const orderData = {
      id: "70.962",
      orderNumber: "ORD/26000887",
      customerProfileId: "1002241",
      customerName: "Carrazza Giovanni",
      deliveryName: "Carrazza Giovanni",
      deliveryAddress: "Via Mezzacapo, 121",
      creationDate: "2026-01-20T12:04:22",
      deliveryDate: "2026-01-21",
      remainingSalesFinancial: null,
      customerReference: null,
      salesStatus: "Ordine aperto",
      orderType: "Ordine di vendita",
      documentStatus: "Nessuno",
      salesOrigin: "Agent",
      transferStatus: "Trasferito",
      transferDate: "2026-01-20",
      completionDate: "2026-01-20",
      discountPercent: "21,49 %",
      grossAmount: "105,60 €",
      totalAmount: "82,91 €"
    };

    db.upsertOrder("user1", orderData);

    // Change status
    orderData.salesStatus = "Consegnato";
    const result = db.upsertOrder("user1", orderData);

    expect(result).toBe("updated");
  });
});
```

**E2E Test Script:**
Create `scripts/test-order-sync-e2e.ts`:
```typescript
import { PDFParserOrdersService } from "../src/pdf-parser-orders-service";
import { OrderDatabaseNew } from "../src/order-db-new";
import { logger } from "../src/logger";

async function testOrderSyncE2E() {
  logger.info("=== Orders Sync E2E Test ===");

  try {
    // Step 1: Parse PDF
    logger.info("[Step 1] Parsing Ordini.pdf...");
    const parserService = PDFParserOrdersService.getInstance();
    const parsedOrders = await parserService.parseOrdersPDF("Ordini.pdf");
    logger.info(`✓ Parsed ${parsedOrders.length} orders`);

    // Step 2: Save to orders-new.db
    logger.info("[Step 2] Saving to orders-new.db...");
    const orderDb = OrderDatabaseNew.getInstance();
    let inserted = 0;
    let updated = 0;
    let skipped = 0;

    for (const order of parsedOrders) {
      const result = orderDb.upsertOrder("test-user", {
        id: order.id,
        orderNumber: order.order_number,
        customerProfileId: order.customer_profile_id,
        customerName: order.customer_name,
        deliveryName: order.delivery_name,
        deliveryAddress: order.delivery_address,
        creationDate: order.creation_date,
        deliveryDate: order.delivery_date,
        remainingSalesFinancial: order.remaining_sales_financial,
        customerReference: order.customer_reference,
        salesStatus: order.sales_status,
        orderType: order.order_type,
        documentStatus: order.document_status,
        salesOrigin: order.sales_origin,
        transferStatus: order.transfer_status,
        transferDate: order.transfer_date,
        completionDate: order.completion_date,
        discountPercent: order.discount_percent,
        grossAmount: order.gross_amount,
        totalAmount: order.total_amount
      });

      if (result === "inserted") inserted++;
      else if (result === "updated") updated++;
      else skipped++;
    }

    logger.info(`✓ Inserted: ${inserted}, Updated: ${updated}, Skipped: ${skipped}`);

    // Step 3: Verify delta detection (re-sync should skip all)
    logger.info("[Step 3] Re-syncing to verify delta detection...");
    let skippedOnResync = 0;

    for (const order of parsedOrders) {
      const result = orderDb.upsertOrder("test-user", {
        id: order.id,
        orderNumber: order.order_number,
        customerProfileId: order.customer_profile_id,
        customerName: order.customer_name,
        deliveryName: order.delivery_name,
        deliveryAddress: order.delivery_address,
        creationDate: order.creation_date,
        deliveryDate: order.delivery_date,
        remainingSalesFinancial: order.remaining_sales_financial,
        customerReference: order.customer_reference,
        salesStatus: order.sales_status,
        orderType: order.order_type,
        documentStatus: order.document_status,
        salesOrigin: order.sales_origin,
        transferStatus: order.transfer_status,
        transferDate: order.transfer_date,
        completionDate: order.completion_date,
        discountPercent: order.discount_percent,
        grossAmount: order.gross_amount,
        totalAmount: order.total_amount
      });

      if (result === "skipped") skippedOnResync++;
    }

    logger.info(`✓ Skipped on re-sync: ${skippedOnResync}/${parsedOrders.length}`);

    // Step 4: Stats
    logger.info("[Step 4] Database stats...");
    const totalCount = orderDb.getTotalCount();
    const lastSync = orderDb.getLastSyncTime();
    logger.info(`✓ Total orders: ${totalCount}`);
    logger.info(`✓ Last sync: ${lastSync?.toISOString()}`);

    logger.info("=== E2E Test Complete ✓ ===");
    process.exit(0);
  } catch (error) {
    logger.error("❌ E2E Test failed", { error });
    process.exit(1);
  }
}

testOrderSyncE2E();
```

**Manual Verification:**
```bash
# 1. Run E2E test
npm run build
node dist/scripts/test-order-sync-e2e.js

# 2. Check health endpoint
curl http://localhost:3000/api/health/pdf-parser-orders

# 3. Verify database
sqlite3 data/orders-new.db "SELECT COUNT(*) FROM orders;"
sqlite3 data/orders-new.db "SELECT id, order_number, customer_name, total_amount FROM orders LIMIT 5;"

# 4. Run unit tests
npm test src/test/order-db-new.test.ts
```

---

## Success Criteria

- [ ] Python parser handles 7-page cycle correctly
- [ ] All 20 fields extracted from PDF
- [ ] Italian date/currency formats converted properly
- [ ] Separate orders-new.db created with schema
- [ ] MD5 hash delta detection working
- [ ] Upsert logic: insert/update/skip functional
- [ ] Node.js service wrapper executes parser
- [ ] Health check endpoint operational
- [ ] Unit tests passing (5+ tests)
- [ ] E2E test completes successfully
- [ ] Performance: < 90s for ~40 orders
- [ ] Memory: < 100MB peak RAM usage

---

## Output

**Files Created:**
1. `scripts/parse-orders-pdf.py` - Python PDF parser (7-page cycle)
2. `src/order-db-new.ts` - New OrderDatabase with delta detection
3. `src/pdf-parser-orders-service.ts` - Node.js wrapper service
4. `src/test/order-db-new.test.ts` - Unit test suite
5. `scripts/test-order-sync-e2e.ts` - E2E test script

**Files Modified:**
1. `src/index.ts` - Add health check endpoint

**Database Created:**
1. `data/orders-new.db` - Separate orders database (20 fields)

**Commits:**
1. `feat(21-01): add orders PDF parser with 7-page cycle support`
2. `feat(21-01): create separate orders database with delta detection`
3. `feat(21-01): add Node.js wrapper for orders parser`
4. `test(21-01): add unit and E2E tests for orders sync`

---
phase: 19-products-sync-optimization
plan: 01
type: execute
---

<objective>
Profile and analyze product sync performance, including image download impact, to identify bottlenecks.

Purpose: Establish baseline performance metrics for ProductSyncService and ImageDownloader, document bottlenecks for optimization.
Output: Performance analysis report with execution times, image download overhead, and optimization recommendations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
@~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Key files:**
@archibald-web-app/backend/src/product-sync-service.ts
@archibald-web-app/backend/src/image-downloader.ts
@archibald-web-app/backend/src/product-db.ts

**Tech stack available:**
- Puppeteer for browser automation
- ImageDownloader for batch image downloads
- SQLite with better-sqlite3
- Winston logger for timing logs

**Existing sync implementation:**
- ProductSyncService.syncProducts() method (~909 lines total file)
- ImageDownloader.downloadBatch() for product images
- Pagination through product list pages
- Checkpoint resume capability
- Similar structure to CustomerSyncService

**Performance considerations:**
- All factors from Phase 18-01 (navigation, waits, scraping)
- Additional: Image download time (batch downloads per page)
- Image download parallelism (how many images at once?)
- Image storage overhead (disk I/O)
- Total sync time = scraping time + image download time

**Profiling approach (same as Phase 18-01):**
- Add timestamp logging at key points
- Measure: total sync time, per-page time, per-product time, image download time
- Separate image download overhead from scraping overhead
- Run full sync and collect metrics
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add performance profiling instrumentation to syncProducts</name>
  <files>
    archibald-web-app/backend/src/product-sync-service.ts
  </files>
  <action>
    Add timing logs throughout syncProducts method (same pattern as Phase 18-01):

    1. At start of method:
    ```typescript
    const syncStartTime = Date.now();
    logger.info('⏱️ [PERF] Product sync started', { startTime: syncStartTime });
    ```

    2. After login:
    ```typescript
    const loginEndTime = Date.now();
    logger.info('⏱️ [PERF] Login completed', {
      duration: loginEndTime - syncStartTime,
      elapsed: `${((loginEndTime - syncStartTime) / 1000).toFixed(2)}s`
    });
    ```

    3. After navigation to product list:
    ```typescript
    const navEndTime = Date.now();
    logger.info('⏱️ [PERF] Navigation to product list completed', {
      duration: navEndTime - loginEndTime,
      elapsed: `${((navEndTime - loginEndTime) / 1000).toFixed(2)}s`
    });
    ```

    4. Inside pagination loop - start of page:
    ```typescript
    const pageStartTime = Date.now();
    logger.info('⏱️ [PERF] Processing page started', {
      page: currentPage,
      timestamp: pageStartTime
    });
    ```

    5. After scraping products (before image download):
    ```typescript
    const scrapingEndTime = Date.now();
    const productsOnPage = products.length;
    logger.info('⏱️ [PERF] Page scraping completed', {
      page: currentPage,
      productsCount: productsOnPage,
      duration: scrapingEndTime - pageStartTime,
      elapsed: `${((scrapingEndTime - pageStartTime) / 1000).toFixed(2)}s`
    });
    ```

    6. After image downloads for page:
    ```typescript
    const imageEndTime = Date.now();
    logger.info('⏱️ [PERF] Image downloads completed', {
      page: currentPage,
      imagesCount: productsOnPage, // Assuming 1 image per product
      duration: imageEndTime - scrapingEndTime,
      elapsed: `${((imageEndTime - scrapingEndTime) / 1000).toFixed(2)}s`,
      avgPerImage: productsOnPage > 0 ? `${((imageEndTime - scrapingEndTime) / productsOnPage).toFixed(0)}ms` : 'N/A'
    });
    ```

    7. End of page processing:
    ```typescript
    const pageEndTime = Date.now();
    logger.info('⏱️ [PERF] Page processing completed', {
      page: currentPage,
      totalDuration: pageEndTime - pageStartTime,
      scrapingTime: scrapingEndTime - pageStartTime,
      imageTime: imageEndTime - scrapingEndTime,
      scrapingPercent: `${(((scrapingEndTime - pageStartTime) / (pageEndTime - pageStartTime)) * 100).toFixed(1)}%`,
      imagePercent: `${(((imageEndTime - scrapingEndTime) / (pageEndTime - pageStartTime)) * 100).toFixed(1)}%`
    });
    ```

    8. At end of sync:
    ```typescript
    const syncEndTime = Date.now();
    const totalDuration = syncEndTime - syncStartTime;
    logger.info('⏱️ [PERF] Product sync completed', {
      totalDuration,
      elapsed: `${(totalDuration / 1000).toFixed(2)}s`,
      pagesProcessed: currentPage,
      productsProcessed: this.progress.productsProcessed,
      avgPerPage: currentPage > 0 ? `${(totalDuration / currentPage / 1000).toFixed(2)}s` : 'N/A',
      avgPerProduct: this.progress.productsProcessed > 0 ? `${(totalDuration / this.progress.productsProcessed).toFixed(0)}ms` : 'N/A'
    });
    ```

    Why separate image timing: Image downloads are significant overhead for product sync, need to measure separately to optimize effectively.
  </action>
  <verify>
    npm run typecheck in backend directory passes

    Manual check:
    1. Start backend
    2. Trigger product sync
    3. Check logs for [PERF] entries with separate scraping and image timings
    4. Verify duration calculations are correct
  </verify>
  <done>
    Performance profiling instrumentation added to syncProducts.
    Timing logs at key points: start, login, navigation, per-page scraping, image downloads, completion.
    Separate timing for scraping vs image download overhead.
    TypeScript compilation passes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Run profiled sync and collect performance data</name>
  <files>
    .planning/phases/19-products-sync-optimization/PERF-DATA.json
  </files>
  <action>
    Execute profiled product sync and capture performance metrics:

    1. Ensure backend running with profiling instrumentation
    2. Trigger full product sync (force sync to bypass recent sync check)
    3. Monitor logs and collect timing data, especially image download overhead
    4. Create PERF-DATA.json with collected metrics:

    ```json
    {
      "testDate": "2026-01-18T...",
      "totalProducts": 200,
      "totalPages": 7,
      "phases": {
        "login": { "duration": 8500, "elapsed": "8.50s" },
        "navigation": { "duration": 3200, "elapsed": "3.20s" },
        "scraping": { "duration": 52000, "elapsed": "52.00s" },
        "imageDownloads": { "duration": 35000, "elapsed": "35.00s" }
      },
      "pageMetrics": [
        {
          "page": 1,
          "products": 30,
          "scrapingDuration": 7500,
          "imageDuration": 4200,
          "totalDuration": 11700,
          "scrapingPercent": "64.1%",
          "imagePercent": "35.9%"
        }
      ],
      "totals": {
        "totalDuration": 98700,
        "elapsed": "98.70s",
        "avgPerPage": "14.10s",
        "avgPerProduct": "494ms",
        "scrapingTime": 52000,
        "imageTime": 35000,
        "scrapingPercent": "52.7%",
        "imagePercent": "35.5%",
        "overheadPercent": "11.8%"
      },
      "bottlenecks": [
        "Image downloads: 35s (35.5% of total) - opportunities for parallelism?",
        "Page scraping: 52s (52.7% of total) - similar to customer sync",
        "Navigation overhead similar to customer sync"
      ],
      "imageDownloadStats": {
        "totalImages": 200,
        "avgPerImage": "175ms",
        "batchSize": 30,
        "parallelism": "unknown (needs investigation)"
      }
    }
    ```

    Use actual values from log output.

    Why detailed image stats: Image downloads are product-specific bottleneck, need specific optimization strategy.
  </action>
  <verify>
    Manual check:
    1. Verify PERF-DATA.json exists with real timing data
    2. Check image download stats are accurate
    3. Verify bottlenecks section identifies slowest operations
  </verify>
  <done>
    PERF-DATA.json created with baseline performance metrics.
    All timing phases documented including separate image download metrics.
    Bottlenecks identified with focus on image optimization opportunities.
  </done>
</task>

<task type="auto">
  <name>Task 3: Analyze ImageDownloader parallelism and create performance report</name>
  <files>
    archibald-web-app/backend/src/image-downloader.ts,
    .planning/phases/19-products-sync-optimization/ANALYSIS.md
  </files>
  <action>
    1. Read ImageDownloader.ts to understand batch download implementation:
       - Check how many images download in parallel (Promise.all? Semaphore limit?)
       - Identify parallelism constraints
       - Check error handling for failed downloads

    2. Create comprehensive performance analysis report in ANALYSIS.md:

    ```markdown
    # Product Sync Performance Analysis

    **Date**: 2026-01-18
    **File**: product-sync-service.ts
    **Method**: syncProducts()

    ## Baseline Metrics

    | Metric | Value |
    |--------|-------|
    | Total products | 200 |
    | Total pages | 7 |
    | Total duration | 98.70s |
    | Avg per page | 14.10s |
    | Avg per product | 494ms |

    ## Phase Breakdown

    | Phase | Duration | % of Total | Notes |
    |-------|----------|-----------|-------|
    | Login | 8.50s | 8.6% | First-time browser initialization |
    | Navigation | 3.20s | 3.2% | Navigate to product list page |
    | Scraping | 52.00s | 52.7% | Data extraction from pages |
    | Image downloads | 35.00s | 35.5% | Batch image downloads (200 images) |

    ## Image Download Analysis

    | Metric | Value |
    |--------|-------|
    | Total images | 200 |
    | Total time | 35.00s |
    | Avg per image | 175ms |
    | Batch size | 30 per page |
    | Parallelism | [FROM CODE REVIEW: e.g., "5 concurrent", "unlimited", etc.] |

    ## Bottlenecks Identified

    ### 1. Image Downloads (35s, 35.5%)
    - **Location**: ImageDownloader.downloadBatch()
    - **Current parallelism**: [FROM CODE REVIEW]
    - **Issue**: Image downloads are serial bottleneck
    - **Recommendation**:
      - Increase parallelism (10-20 concurrent downloads)
      - Skip re-downloading existing images (check file exists)
      - Lazy image downloads (download in background after sync completes)

    ### 2. Page Scraping (52s, 52.7%)
    - Similar bottlenecks to customer sync (Phase 18-01)
    - Apply same optimizations: networkidle2 → domcontentloaded, reduce setTimeout

    ### 3. Navigation Overhead
    - Same as customer sync, same optimizations apply

    ## Optimization Opportunities

    ### High Impact (>10s potential savings)
    1. **Optimize image parallelism**: -10-15s (increase concurrent downloads)
    2. **Skip existing images**: -5-10s (check file exists before download)
    3. **Lazy image downloads**: Move to background (user-perceived time: -35s)
    4. **Optimize page navigation waits**: -5-10s (same as Phase 18-05)

    ### Medium Impact (5-10s potential savings)
    5. **Reduce explicit setTimeout delays**: -8-12s (same as Phase 18-05)
    6. **Batch product data extraction**: -3-5s (single DOM query)

    ## Estimated Optimization Potential

    | Scenario | Current | Optimized | Improvement |
    |----------|---------|-----------|-------------|
    | Conservative (sync images) | 98.7s | 68s | -30.7s (-31%) |
    | Moderate (parallel images) | 98.7s | 52s | -46.7s (-47%) |
    | Aggressive (lazy images) | 98.7s | 38s | -60.7s (-62%) |
    | User-perceived (lazy bg) | 98.7s | 38s | -60.7s (-62%) |

    **Recommended approach**: Lazy image downloads in background
    - Sync completes in ~38s (scraping only)
    - Images download in parallel background after sync
    - User can use product data immediately
    - Best of both worlds: fast sync + complete data

    ## Next Steps

    1. **Phase 19-02**: Add retry logic and health monitoring
    2. **Phase 19-03**: Implement incremental sync + image optimization
    3. **Phase 19-05**: Apply optimizations
       - Increase image download parallelism
       - Skip existing images
       - Optional: Lazy background image downloads
       - Apply Phase 18 optimizations (navigation, setTimeout)
    ```

    Adjust based on actual PERF-DATA.json and ImageDownloader code review.

    Why lazy images strategy: Products are usable without images immediately, images can download in background, massive user-perceived performance gain.
  </action>
  <verify>
    Manual check:
    1. Verify ImageDownloader parallelism analyzed correctly
    2. Check ANALYSIS.md includes image-specific optimization recommendations
    3. Ensure lazy image download strategy is documented
  </verify>
  <done>
    ImageDownloader parallelism analyzed.
    ANALYSIS.md created with comprehensive performance report.
    Image-specific bottlenecks identified.
    Lazy background image download strategy recommended.
    Optimization potential: 31-62% improvement depending on strategy.
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run typecheck` passes in backend directory
- [ ] Performance profiling instrumentation added to syncProducts
- [ ] Separate timing for scraping vs image downloads
- [ ] PERF-DATA.json created with real metrics including image stats
- [ ] ImageDownloader parallelism analyzed
- [ ] ANALYSIS.md created with image-specific optimization recommendations
- [ ] No TypeScript errors
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Performance profiling instrumentation functional with image timing
- Baseline metrics collected (total ~98-100s estimated)
- Image download overhead measured separately (estimated 30-40% of total)
- ImageDownloader parallelism analyzed
- Bottlenecks identified with image-specific optimizations
- Lazy background image download strategy documented
- Analysis report provides clear roadmap for optimization
- No errors or warnings introduced
  </success_criteria>

<output>
After completion, create `.planning/phases/19-products-sync-optimization/19-01-SUMMARY.md`:

# Phase 19 Plan 01: Product Sync Performance Analysis Summary

**[Substantive one-liner - what shipped, not "phase complete"]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `archibald-web-app/backend/src/product-sync-service.ts` - Description
- `archibald-web-app/backend/src/image-downloader.ts` - Description (if modified)
- `.planning/phases/19-products-sync-optimization/PERF-DATA.json` - Description
- `.planning/phases/19-products-sync-optimization/ANALYSIS.md` - Description

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Step

Ready for 19-02-PLAN.md (Background Sync Enhancement)
</output>
